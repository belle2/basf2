#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""\
Check a given basf2 root file for problems.

PERFORMED CHECKS:
- File is readable (file_readable)
- File contains event and persistent tree (contains_tree, contains_persistent)
- Event tree contains event meta data (eventmetadata_readable)
- Persistent tree contains file metadata (filemetadata_readable)
- Number of entries in event tree == number of events in file metadata == expected_no_of_events (entries_eq_filemetedata)
- If the expected size is given: abs(total_file_size/(#events*expected_event_size) - 1) < relative_uncertainty (eventsize_eq_expectation)
RETURN CODE:
    0 if all checks succeeded, 1 otherwise. Details about about check failures are printed on standard output.
"""
#TODO:
#- If branches are given: Event tree contains the given branches
#- If log is give: Grep for suspicious messages like Fatal, segmentation
#fault, etc. [although this should be caught by the basf2 return code.]


import sys
import os
import argparse
import json
from contextlib import redirect_stdout
import ROOT

parser = argparse.ArgumentParser(description=__doc__, formatter_class=argparse.RawDescriptionHelpFormatter)
parser.add_argument("-n", "--events", type=int, dest='expected_no_of_events', default=None, help="Expected number of events")
parser.add_argument("-s", "--size", type=float, dest='expected_event_size', metavar=('EXPECTED_EVENT_SIZE_KIB', 'RELATIVE_UNCERTAINTY'), default=None, nargs=2,
                    help="Expected size per event (kiB), with maximal relative uncertainty. Check is passed when abs(total_file_size/(#events*expected_event_size) - 1) < relative_uncertainty")
parser.add_argument("--json", action='store_true', dest='json_output', default=False, help="Provide dictionary of passed checks and file statistics in JSON format on standard output. Checks are only included when actually run, and receive a boolean value indicating success.")
parser.add_argument("FILE", type=str, help="The basf2 .root file to check. http:// and root:// URLs are also supported.")


def checkFile(filename, expected_no_of_events, expected_event_size):
    """
    Runs checks on given filename, returns dictionaries with passed checks
    and file statistics.
    """
    checks_passed = dict()
    stats = dict()
    root_file = ROOT.TFile.Open(filename)

    checks_passed['file_readable'] = bool(root_file) and root_file.IsOpen()
    if not checks_passed['file_readable']:
        return checks_passed, stats
    try:
        stats['compression_algorithm'] = root_file.GetCompressionAlgorithm()
        stats['compression_level'] = root_file.GetCompressionLevel()
        stats['compression_factor'] = root_file.GetCompressionFactor()

        checks_passed['contains_tree'] = False
        tree = root_file.Get('tree')
        if tree:
            nevents = tree.GetEntries()
            checks_passed['contains_tree'] = True
            stats['events'] = nevents

        persistent = root_file.Get('persistent')
        checks_passed['contains_persistent'] = bool(persistent)

        checks_passed['filemetadata_readable'] = False
        if persistent.GetEntry(0) > 0:
            filemetadata = persistent.FileMetaData.Clone()
            nevents_metadata = filemetadata.getNEvents()
            checks_passed['filemetadata_readable'] = True

            checks_passed['entries_eq_filemetedata'] = nevents_metadata == nevents

        if expected_no_of_events is not None:
            checks_passed['entries_eq_expectation'] = nevents == expected_no_of_events
            if not checks_passed['entries_eq_expectation']:
                print ('expected %d events, but file contains %d!' % (expected_no_of_events, nevents))

        checks_passed['eventmetadata_readable'] = False
        if tree.GetEntry(0) > 0:
            eventmetadata = tree.EventMetaData.Clone()
            eventmetadata.getEvent()
            checks_passed['eventmetadata_readable'] = True

        size_kib = root_file.GetSize() / 1024.0
        size_kib_per_event = size_kib / nevents
        stats['filesize_kib'] = size_kib
        stats['size_per_event_kib'] = size_kib_per_event
        if expected_event_size is not None:
            exp_size_kib, rel_uncertainty = expected_event_size
            dev = abs(size_kib_per_event / exp_size_kib - 1)
            checks_passed['eventsize_eq_expectation'] = dev < rel_uncertainty
            if not checks_passed['eventsize_eq_expectation']:
                print ('Size per event (%g kiB) differs from expectation (deviation: %g >= %g)' % (size_kib_per_event, dev, rel_uncertainty))
    except:
        # at least one of the checks should have failed
        assert not all(checks_passed.values())

    return checks_passed, stats


if __name__ == "__main__":
    args = parser.parse_args()
    if args.json_output:
        # suppress other things on standard output
        with redirect_stdout(os.devnull):
            checks_passed, stats = checkFile(args.FILE, args.expected_no_of_events, args.expected_event_size)
        print(json.dumps({'checks_passed': checks_passed, 'stats': stats}, sort_keys=True, indent=2))
    else:
        checks_passed, stats = checkFile(args.FILE, args.expected_no_of_events, args.expected_event_size)

    checks_failed = [c for (c, ok) in checks_passed.items() if not ok]
    if not args.json_output:
        if checks_failed:
            print('The following checks FAILED: ' + ' '.join(checks_failed))

    if checks_failed:
        sys.exit(1)

