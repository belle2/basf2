#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Script to upload local database to ConditionsDB.

This script takes a local database file and will upload all payloads defined in
this file to the ConditionsDB and create iovs for each payload. It assumes that
all tags, experiments and runs already exist.
"""

from basf2 import *
import argparse
from conditions_db import ConditionsDB, calculate_checksum
from concurrent.futures import ThreadPoolExecutor
import pprint
import re


def natural_sortkey(element):
    """Return sort key to sort elements in natural order. This will make sure
    that text containing digits is in the expected order even if the numbers are
    not zero padded.

        >>> natural_sortkey("a10b9")
        ('a', 10, 'b', 9, '')
        >>> sorted(['a11', 2, '1', 'a10', 'a9'], key=natural_sortkey)
        ['1', 2, 'a9', 'a10', 'a11']

    """
    return tuple(int(text) if text.isdigit() else text.lower() for text in re.split('(\d+)', str(element)))


class LocalDatabaseEntry:
    """Class to keep information about an entry in the local database file"""
    def __init__(self, line, basedir):
        """Create new entry from line in database file"""
        name, revision, iov = line.split()
        name = name.split("/")
        #: package name
        self.package = name[0]
        #: module name
        self.module = name[1]
        #: filename
        self.filename = os.path.join(basedir, "{package}_{module}_rev_{revision}.root".format(
            package=self.package, module=self.module, revision=revision,
        ))
        iov = [int(e) for e in iov.split(",")]
        #: experiment/run of the first run
        self.firstRun = {"exp": iov[0], "run": iov[1], "id": None}
        #: experiment/run of the final run
        self.finalRun = {"exp": iov[2], "run": iov[3], "id": None}
        #: variable for checksum, calculated on first access
        self.__checksum = None
        #: object to uniquely identify this entry (payload + iov)
        self.__id = (self.package, self.module) + tuple(iov)
        #: payload id, to be filled later
        self.payload = None
        #: iov id, to be filled later
        self.iov = None

    @property
    def checksum(self):
        """Return checksum, calculated on first access"""
        if self.__checksum is None:
            self.__checksum = calculate_checksum(self.filename)
        return self.__checksum

    def __repr__(self):
        """Convert to useful string representation"""
        return repr(self.__id + (self.filename,))

    def __eq__(self, other):
        """Compare to other entries, only consider package, module and iov for equality"""
        return self.__id == other.__id

    def __le__(self, other):
        """Compare to other entries, only consider package, module and iov for equality"""
        return self.__id <= other.__id

    def __lt__(self, other):
        """Compare to other entries, only consider package, module and iov for equality"""
        return self.__id < other.__id

    def __hash__(self):
        """Provide hash function to be able to create a set"""
        return hash(self.__id)


if __name__ == "__main__":
    # modify logging to remove the useless module: lines
    for level in LogLevel.values.values():
        logging.set_info(level, LogInfo.LEVEL | LogInfo.MESSAGE | LogInfo.TIMESTAMP)

    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument("--tag", required=True, metavar="TAGNAME",
                        help="Global tag to use for iov creation")
    parser.add_argument("dbfile", metavar="DATABASEFILE",
                        help="Database file containing local list of iovs")
    parser.add_argument("dbdir", nargs="?", metavar="DATABASEDIR",
                        help="Directory for the payloads. Defaults to the directory "
                        "of the database file")
    parser.add_argument("--exp-format", default=None, metavar="FORMAT",
                        help="Format for the experiment name, e.g. 'BELLE_exp%%d' "
                        "to convert experiment number 7 to 'BELLE_exp7' before lookup. "
                        "If not given experiment numbers will be used as they are")
    parser.add_argument("-j", type=int, default=1, dest="nprocess",
                        help="Number of concurrent connections to use for database "
                        "connection (default: %(default)s)")
    parser.add_argument("--retries", type=int, default=3,
                        help="Number of retries on connection problems (default: "
                        "%(default)s)")
    parser.add_argument("--max-exp", default=None, type=int,
                        help="Maximum experiment number to be set for iovs which "
                        "don't have an end experiment")
    parser.add_argument("--base-url", default=ConditionsDB.BASE_URL,
                        help="URI for the base of the REST API (default: %(default)s)")
    parser.add_argument("--ignore-existing", action="store_true", default=False,
                        help="Don't check if payloads or iovs already exist in database. "
                        "Speeds up initialization as the list of existing payloads "
                        "doesn't need to be downloaded. Can be used on first upload "
                        "but the script cannot resume an upload if this option is given")

    args = parser.parse_args()

    # need at least one worker thread
    if args.nprocess <= 0:
        B2WARNING("-j must be larger than zero, ignoring")
        args.nprocess = 1

    B2INFO("Using %d simultaneous connections" % args.nprocess)

    # create conditions db interface
    db = ConditionsDB(args.base_url, args.nprocess, args.retries)

    # and get the id for the global tag
    tagId = db.get_globalTagId(args.tag)
    if tagId is None:
        sys.exit(1)

    # make sure the database file exists
    if not os.path.exists(args.dbfile):
        B2FATAL("Given database file does not exist")

    # and set the directory if not given on the command line
    if args.dbdir is None:
        args.dbdir = os.path.dirname(args.dbfile)

    # first create a list of payloads and a set of all experiments we encountered
    # also count the missing files
    entries = []
    experiments = set()
    missing = 0
    with open(args.dbfile) as dbfile:
        for line in dbfile:
            entry = LocalDatabaseEntry(line, args.dbdir)
            if not os.path.exists(entry.filename):
                B2ERROR("Cannot find payload file %s" % entry.filename)
                missing += 1
            entries.append(entry)
            experiments.add(entry.firstRun["exp"])
            experiments.add(entry.finalRun["exp"])

    # ok, we couldn't find all payload files, no need to continue
    if missing > 0:
        B2ERROR("Some payload files could not be found, exiting")
        sys.exit(1)

    # now we could have more than one payload with the same iov so let's go over
    # it again and remove duplicates but keep the last one for each
    entries = sorted(set(reversed(entries)))

    # check if we have unbound experiments
    if -1 in experiments:
        # if so the --max-exp argument is needed to find out what we should use
        # for -1
        if args.max_exp is None:
            B2ERROR("database file contains unbound final experiment which isn't "
                    "supported by ConditionsDB. Please specify --max-exp to indicate "
                    "which experiment should be used in its stead. Exiting.")
            B2INFO("Existing experiments are: " + ", ".join(str(e) for e in sorted(db.get_experiments().keys(), key=natural_sortkey)))
            sys.exit(1)
        # so replace the -1 in the set
        experiments.remove(-1)
        experiments.add(args.max_exp)

    # and just for fun, sort the experiments
    experiments = sorted(experiments)

    # now let's make sure all experiments and runs exist and find out which
    # payloads need uploading. For this we need a list of existing payloads and
    # iovs from the database which is quite large so let's make this optional.
    #
    # but for now we definitely need the ids for runs. If the database scheme
    # would get simplified we could do even without that.

    def expName(exp):
        """small helper to format experiment name if such an argument is given"""
        if args.exp_format is None:
            return exp
        return args.exp_format % exp

    existing_runs = {}
    existing_payloads = {}
    existing_iovs = {}
    # multithreading for the win ...
    with ThreadPoolExecutor(max_workers=args.nprocess) as pool:
        B2INFO("Downloading information about existing runs, payloads and iovs...")
        # if we want to check for existing payloads/iovs we shedule the download of
        # the full payload list. And write a message as each completes
        if not args.ignore_existing:
            payloads_future = pool.submit(db.get_payloads)
            payloads_future.add_done_callback(lambda x: B2INFO("got info on existing payloads"))
            iovs_future = pool.submit(db.get_iovs, args.tag)
            iovs_future.add_done_callback(lambda x: B2INFO("got info on existing iovs"))
        # now get the list of runs for all experiments we saw in the database
        # file
        exp_runs = pool.map(lambda x: db.get_runs(expName(x)), experiments)
        # and build up a dictionary with all experiments/runs
        for exp, runs in zip(experiments, exp_runs):
            B2INFO("got run ids for experiment %s" % exp)
            existing_runs[exp] = runs
        # now we just wait for the list of payloads and or iov if requested
        if not args.ignore_existing:
            existing_payloads = payloads_future.result()
            existing_iovs = iovs_future.result()

    # Ok, so let's check all payloads and see if we need to upload, create iovs
    # or do nothing for each entry. First we have to convert exp/run numbers to
    # runId, removing unlimited experiments/runs in the process.

    def update_run(run):
        """Small helper function to update a given run with the runId
        corresponding to the exp/run numbers"""
        try:
            if run["exp"] == -1:
                run["exp"] = args.max_exp
            if run["run"] == -1:
                run["run"] = max(existing_runs[run["exp"]])
                B2INFO("Replacing unbound run for experiment {exp} with {run}".format(**run))
            run["id"] = existing_runs[run["exp"]][run["run"]]
            return 0
        except KeyError:
            B2ERROR("Experiment %d, Run %d doesn't exist in the database")
            return 1

    errors = 0
    for entry in entries:
        # update entry to add run id to first and final run, count the errors
        errors += update_run(entry.firstRun)
        errors += update_run(entry.finalRun)
        # check if the final run is at least equal to the first run
        if entry.firstRun["exp"] > entry.finalRun["exp"] or \
                (entry.firstRun["exp"] == entry.finalRun["exp"] and
                 entry.firstRun["run"] > entry.finalRun["run"]):
            B2ERROR("Invalid iov: final run ({final[exp]},{final[run]}) is before "
                    "first run ({first[exp]},{first[run]}). Make sure --max-exp "
                    "is correct if given".format(first=entry.firstRun, final=entry.finalRun))
            errors += 1

        # check for existing payload using package,module,checksum as key
        payload_key = (entry.package, entry.module, entry.checksum)
        if payload_key in existing_payloads:
            entry.payload = existing_payloads[payload_key]
            B2INFO("%s already existing in database, skipping upload" % entry.filename)
        # check for existing iov using (payload id, first run id, final run id)
        iov_key = (entry.payload, entry.firstRun["id"], entry.finalRun["id"])
        if iov_key in existing_iovs:
            entry.iov = existing_iovs[iov_key]
            B2INFO("iov for %s already existing in database, skipping iov creation" % entry.filename)

    # if we have errors we refuse to continue
    if errors > 0:
        B2ERROR("Errors when checking contents of database file, exiting")
        sys.exit(1)

    # OK, finally we can do the upload. So let's define a function which uploads
    # if needed and just call this function for all entries because
    # multithreading

    def upload(entry):
        """Helper function to handle uploading and iov creation in multiple threads"""
        # if the entry doesn't have a payload id then upload the file and obtain
        # the new payload id
        if entry.payload is None:
            B2INFO("Uploading %s" % entry)
            entry.payload = db.create_payload(entry.package, entry.module, entry.filename, entry.checksum)

        # if upload was successful (or preexisting payload) but if we don't have an iov then create one
        if entry.payload is not None and entry.iov is None:
            B2INFO("Creating iov for %s" % entry)
            entry.iov = db.create_iov(tagId, entry.payload, entry.firstRun["id"], entry.finalRun["id"])

        # return the modified entry
        return entry

    with ThreadPoolExecutor(max_workers=args.nprocess) as pool:
        results = pool.map(upload, entries)
        # let's loop over the result to see any exceptions
        for entry in results:
            # nothing to do, just need to iterate to get execptions to execute.
            # There shouldn't be any
            pass
