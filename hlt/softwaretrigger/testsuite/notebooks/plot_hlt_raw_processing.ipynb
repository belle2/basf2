{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import glob\n",
    "import os\n",
    "import gzip\n",
    "import configparser\n",
    "import matplotlib\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "font = {'family' : 'normal',\n",
    "        'size'   : 18}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "# show all columns in outputs\n",
    "pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gc_workdir = \"../hlt_raw_processing_evp_scripts_phase2_cosmics_reco_monitor_novxd/work.hlt_raw_processing/\"\n",
    "gc_workdir = \"../hlt_raw_processing_expressreco_phase2_cosmics_reco/work.hlt_raw_processing/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def read_app_log(fname, fname_uncomp):\n",
    "    # extract app log files, if present\n",
    "    if not os.path.isfile(fname_uncomp) and os.path.isfile(fname):\n",
    "        print(\"Uncompressing {}\".format(fname))\n",
    "        with open(fname_uncomp, 'wb+') as f_out, gzip.open(fname, 'rb') as f_in:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "    app_stderr = \"\"\n",
    "    if os.path.isfile(fname_uncomp):\n",
    "        with open(fname_uncomp, 'r') as f:\n",
    "            line_count = 0\n",
    "            for line in f:\n",
    "                line_count += 1\n",
    "                app_stderr = app_stderr + str(line)\n",
    "    return app_stderr\n",
    "\n",
    "def gc_parse_jobresults(folder):\n",
    "    job_folders = glob.glob(os.path.join(gc_workdir, \"output\") + \"/job_*/\")\n",
    "    \n",
    "    df = pandas.DataFrame()\n",
    "    \n",
    "    for job_folder in job_folders:\n",
    "        job_info_file = os.path.join(job_folder, \"job.info\")\n",
    "        gc_stdout_file = os.path.join(job_folder, \"gc.stdout\")\n",
    "        app_stdout_file_uncomp = os.path.join(job_folder, \"job.stdout\")\n",
    "        app_stdout_file = app_stdout_file_uncomp + \".gz\"\n",
    "        app_stderr_file_uncomp = os.path.join(job_folder, \"job.stderr\")\n",
    "        app_stderr_file = app_stderr_file_uncomp + \".gz\"\n",
    "        \n",
    "        myvars = {}\n",
    "        with open(job_info_file) as myfile:\n",
    "            for line in myfile:\n",
    "                name, var = line.partition(\"=\")[::2]\n",
    "                myvars[name.strip()] = var.strip()\n",
    "\n",
    "        job_id = int(myvars[\"JOBID\"])\n",
    "        job_exitcode = int(myvars[\"EXITCODE\"])\n",
    "                \n",
    "        input_file_name = None\n",
    "        # read GC output file\n",
    "        if os.path.isfile(gc_stdout_file):\n",
    "            with open(gc_stdout_file) as myfile:\n",
    "                for line in myfile:\n",
    "                    if line.startswith(\"export FILE_NAMES\"):\n",
    "                        name, var = line.partition(\"=\")[::2]\n",
    "                        input_file_name = var.strip('\"')\n",
    "\n",
    "        app_stderr = read_app_log( app_stderr_file, app_stderr_file_uncomp)\n",
    "        app_stdout = read_app_log( app_stdout_file, app_stdout_file_uncomp)        \n",
    "        \n",
    "        ser = pandas.Series({\"exitcode\" : job_exitcode,\n",
    "                             \"jobid\": job_id,\n",
    "                             \"input_file_name\": input_file_name,\n",
    "                             \"app_stderr_lines\" : app_stderr.count(\"\\n\"),\n",
    "                             \"app_stderr\" : app_stderr,\n",
    "                             \"app_stdout_lines\" : app_stdout.count(\"\\n\"),\n",
    "                             \"app_stdout\" : app_stdout})\n",
    "        df = df.append(ser, ignore_index=True)                 \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gc_parse_jobresults(gc_workdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract experiment and run numbers from file names\n",
    "df[\"experiment\"] = df.input_file_name.str.extract('(?P<experiment>e0[0-9]*)', expand=True)\n",
    "df[\"experiment\"] = df[\"experiment\"].str.replace(\"e\",\"\").astype('float')\n",
    "df[\"run\"] = df.input_file_name.str.extract('(?P<run>r0[0-9]*)', expand=True)\n",
    "df[\"run\"] = df[\"run\"].str.replace(\"r\",\"\").astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.run.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.exitcode.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.exitcode.value_counts()\n",
    "# https://ekptrac.physik.uni-karlsruhe.de/trac/grid-control/wiki/ErrorCodes\n",
    "# 107 \tkilled by batch system \n",
    "# 121 -> HUGE log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.app_stderr_lines.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.app_stdout_lines.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_failed = df[df.exitcode != 107]#[df.exitcode != 0]\n",
    "df_failed = df_failed[df_failed.exitcode != 0]\n",
    "df_failed[\"explained\"] = False\n",
    "df_failed[\"fail_reason\"] = \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_class = {\"trackfit_consistency\" : [\"fi->checkConsistency()\", True],\n",
    "               \"time_extract_crash\" : [\"extractTrackTimeFrom\", True],\n",
    "                \"cant_open_input\" : [\"Couldn't open input file\", False]}\n",
    "\n",
    "for (name, val) in error_class.items():\n",
    "    check_string = val[0]\n",
    "    basf2_fault = val[1]\n",
    "    # check for the problem in the std err\n",
    "    df_failed[\"explained\"] = df_failed[\"explained\"] | df_failed.app_stderr.str.count(check_string) > 0\n",
    "    this_count_err = df_failed.app_stderr.str.count(check_string).sum()\n",
    "\n",
    "    # check for the problem in the std out\n",
    "    df_failed[\"explained\"] = df_failed[\"explained\"] | df_failed.app_stdout.str.count(check_string) > 0\n",
    "    this_count_out = df_failed.app_stdout.str.count(check_string).sum()\n",
    "    \n",
    "    # store the failure reason \n",
    "    df_failed.loc[df_failed.app_stdout.str.count(check_string) > 0,\"fail_reason\"] = name\n",
    "    df_failed.loc[df_failed.app_stderr.str.count(check_string) > 0,\"fail_reason\"] = name\n",
    "    \n",
    "    print (\"{} occurs {} times in stderr and {} in stdout. This is basf2's fault: {}\".format(name, this_count_err, this_count_out, basf2_fault))\n",
    "\n",
    "print(\"NOTE: there might be double counting, if the string which is searched for is two times in the strack trace.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for fr in df_failed.fail_reason.unique():\n",
    "    print (\"## File names for fail reason {} ##\".format(fr))\n",
    "    for fname in df_failed[df_failed.fail_reason == fr].input_file_name:\n",
    "        print(fname.replace('\"',\"\"), end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_range = (0, 360)\n",
    "success_bins = 80\n",
    "\n",
    "f = plt.figure(figsize=(10,10))\n",
    "ax = df.run.hist(label=\"All completed input files\", range=success_range, bins=success_bins)\n",
    "df_failed_basf2fault.run.hist(label=\"Failed Reconstruction\", range=success_range, bins=success_bins)\n",
    "plt.legend()\n",
    "ax.set_title(\"HLT Reco NoVXD Release 1.1 Experiment 2\")\n",
    "ax.set_xlabel(\"Run Number\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
