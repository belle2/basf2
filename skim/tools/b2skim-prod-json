#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""\
.. Note::
   This tool is intended for use by skim production managers, not by skim liaisons.

``%(prog)s`` is a tool for producing grid production requests in the format required by the
`production system <https://confluence.desy.de/display/BI/Production+Definition>`_.

YAML files are used by this tool to define the LPNs of datasets. Below are examples of valid YAML
entries for data and MC.

.. code-block:: yaml

    ## Example of a YAML file for data:
    proc9_exp3r1:
        sampleLabel: proc9_exp3
        LPNPrefix: /belle/Data
        inputReleaseNumber: release-03-02-02
        prodNumber: prod00008530
        inputDBGlobalTag: DB00000654
        procNumber: proc9
        experimentNumber: e0003
        beamEnergy: 4S
        inputDataLevel: mdst
        runNumbers:
            - r02724
            - r02801
            - r02802

    proc9_exp3r2:
        sampleLabel: proc9_exp3
        LPNPrefix: /belle/Data
        inputReleaseNumber: release-03-02-02
        prodNumber: 8530  # Can pass prod ID without prod0000 at start
        inputDBGlobalTag: 654  # Can pass the number without DB00000 at start
        procNumber: proc9
        experimentNumber: e0003
        beamEnergy: 4S
        inputDataLevel: mdst
        runNumbers:
            - r03237
            - r03238
            - r03239


    ## Example of a YAML file for MC:
    MC12b_mixed:
        sampleLabel: MC12_mixedBGx1
        LPNPrefix: /belle/MC
        inputReleaseNumber: release-03-01-00
        inputDBGlobalTag: DB00000547
        mcCampaign: MC12b
        prodNumber: prod00007392
        experimentNumber: s00/e1003
        beamEnergy: 4S
        mcType: mixed
        mcBackground: BGx1
        inputDataLevel: mdst
        runNumber: r00000


    MC12b_charged:
        sampleLabel: MC12_chargedBGx1
        LPNPrefix: /belle/MC
        inputReleaseNumber: release-03-01-00
        inputDBGlobalTag: 547  # Can pass the number without DB00000 at start
        mcCampaign: MC12b
        prodNumber:
            - 7799  # Can pass list of prod numbers without prod0000 at start
            - 7802
        experimentNumber: s00/e1003
        beamEnergy: 4S
        mcType: charged
        mcBackground: BGx1
        inputDataLevel: mdst
        runNumber: r000000

To produce JSON files for a list of combined skims, pass this tool the YAML file and the names of
the skims. The combined skims must be defined in `skim.registry.combined_skims`. The other required
arguments include the starting prod ID, skim campaign, intended release to be used, and base
directory of the repository to output the JSON files in.

This tool is designed to work with the ``skimStats.json`` output of ``b2skim-stats-print`` (see
:ref:`testing-skims`). The YAML files can be used to specify which sample statistics are to be used
for each dataset, with the keyword ``sampleLabel``---this must match one of the sample labels used by
the skim statistics tools. ``skimStats.json`` must be present in the current directory when this
tool is run.

--epilog--
.. rubric:: Example usage

* Produce requests for EWP and feiSLCombined skims on proc9::

    $ %(prog)s Registry_proc9.yaml -s EWP feiSLCombined --data -n 101 -c SKIMDATAx1 -r release-04-01-01 -o B2P/data/

* Produce requests for EWP on MC13, with one LPN per JSON file::

    $ %(prog)s Registry_MC13.yaml -1 -s EWP --data -n 101 -c SKIMDATAx1 -r release-04-01-01 -o B2P/data/

* Produce requests for EWP on MC13, using local skim module script::

    $ %(prog)s Registry_MC13.yaml -l ewp_local.py -s EWP --data -n 101 -c SKIMDATAx1 -r release-04-01-01 -o B2P/data/
"""

__author__ = "Phil Grace, Racha Cheaib"
__email__ = "philip.grace@adelaide.edu.au, rachac@mail.ubc.ca"


import argparse
from functools import lru_cache
from itertools import product
import json
from pathlib import Path
import sys
import yaml

from basf2 import B2ERROR, B2INFO, B2WARNING
from conditions_db import ConditionsDB, encode_name
from ROOT import PyConfig
# Importing ROOT in skimExpertFunctions has the side-effect of hijacking argument parsing
PyConfig.IgnoreCommandLineOptions = True
from skimExpertFunctions import encodeSkimName
from skim.registry import combined_skims as combinedSkimsInfo


def read_registry_yaml(sampleRegistryYaml, mc):
    """Load in the YAML file as a dict. Checks that all expected values
    present before proceeding.

    Args:
        sampleRegistryYaml (str): Location of the registry YAML file to read in.
        mc (bool): Are these JSON files being produced for MC skims?

    Returns:
        sampleRegistry (dict): The input data/MC registry as a dict.

    .. note::

        The YAML file needs to contain certain values for this to work. The
        top-level names are used throughout this script as labels for each set
        of data/MC. The key "sampleLabel" must correspond to a sample label used
        in `b2skim-stats-print`, so that the performance statistics can be
        retrieved from ``skimStats.json``. The remaining keys are used to
        construct the LPNs of the input datasets.
    """
    with open(sampleRegistryYaml) as sampleRegistryFile:
        sampleRegistry = yaml.safe_load(sampleRegistryFile)

    verify_registry(sampleRegistry, mc)

    return sampleRegistry


def get_skim_stats_dict():
    """Read in the JSON output of ``b2skim-stats-print`` into a dict.

    Returns:
        skimStatsDict (dict): A dict containing the tested skim statistics.
    """
    # Assumes that skimStats.json is in the current directory
    try:
        with open("skimStats.json") as skimStatsFile:
            skimStatsDict = json.load(skimStatsFile)
    except FileNotFoundError:
        B2ERROR("Could not find required file `skimStats.json` in current directory.\n"
                "          Please run `b2skim-stats-print` with the `-J` flag, and put\n"
                "          the output `skimStats.json` in the current directory.")
        sys.exit(1)

    return skimStatsDict


def verify_registry(sampleRegistry, mc):
    """Check that the registry contains all the values that are expected. If a
    value is missing, print an error and exit.

    Args:
        sampleRegistry (dict): The input data/MC registry as a dict.
        mc (bool): Are these JSON files being produced for MC skims?
    """
    expectedMCEntries = ["sampleLabel", "LPNPrefix", "inputReleaseNumber",
                         "inputDBGlobalTag", "mcCampaign", "prodNumber",
                         "experimentNumber", "beamEnergy", "inputDataLevel",
                         "mcType", "mcBackground", "runNumber"]
    expectedDataEntries = ["LPNPrefix", "inputReleaseNumber", "inputDBGlobalTag",
                           "procNumber", "prodNumber", "experimentNumber",
                           "beamEnergy", "inputDataLevel", "runNumbers"]

    missingEntries = []
    if mc:
        missingEntries = [(sampleLabel, expectedEntry)
                          for (sampleLabel, sampleInfo) in sampleRegistry.items()
                          for expectedEntry in expectedMCEntries
                          if expectedEntry not in sampleInfo.keys()]
    else:
        missingEntries = [(sampleLabel, expectedEntry)
                          for (sampleLabel, sampleInfo) in sampleRegistry.items()
                          for expectedEntry in expectedDataEntries
                          if expectedEntry not in sampleInfo.keys()]

    if missingEntries:
        for sampleLabel, missingEntry in missingEntries:
            B2ERROR(f"Missing entry {missingEntry} for registry entry {sampleLabel}.")
        sys.exit(1)


def verify_stats_dict(args, sampleRegistry, skimStatsDict):
    """Verify that the required statistics are present in the stats dict. If any
    issues are found, print an error and exit.

    Args:
        args (argparse.ArgumentParser): An argparser expected to contain values
            for campaign name, starting prod number, and list of skims. Can also
            be any object which has these as attributes.
        sampleRegistry (dict): The input data/MC registry as a dict.
        skimStatsDict (dict): A dict containing the tested skim statistics.
    """
    skims = args.skims
    statistics = ["cpuTimePerEvent", "udstSizePerSkimmedEvent"]
    sampleLabels = [sampleInfo["sampleLabel"] for sampleInfo in sampleRegistry.values()]

    # Verify that all the requested skims have statistics listed
    missingSkims = [skim for skim in skims
                    if skim not in skimStatsDict.keys()]
    if missingSkims:
        for missingSkim in missingSkims:
            B2ERROR(f"Cannot find stats for {missingSkim} skim in skimStats.json.\n"
                    "          Perhaps you misspelled it or forgot to produce the\n"
                    "          stats with `b2skim-stats-print`?")
        sys.exit(1)

    # Verify that all the requested samples were tested, and returned non-None values
    for skim, statistic, sampleLabel in product(skims, statistics, sampleLabels):
        try:
            statValue = skimStatsDict[skim][statistic][sampleLabel]
            if statValue is None:
                B2ERROR(f"The value for {statistic} for {skim} skim on {sampleLabel} sample"
                        "is `None`! This value is required for the produced JSON files.")
                sys.exit(1)
        except KeyError:
            B2ERROR(f"Missing value for {statistic} for {skim} skim on {sampleLabel} sample."
                    "Perhaps you misspelled it or forgot to produce the stats "
                    "with `b2skim-stats-print`.")
            sys.exit(1)


def get_base_directory(args):
    """Read the output base directory from the argparse arguments, and return
    that location as a `pathlib.Path` object. Checks that the given directory
    exists, and will print an error and exits if it is not.

    Args:
        args (argparse.ArgumentParser): An argument parser assumed to have the
            attribute `output_base_directory`.

    Returns:
        baseDirectory (pathlib.Path): The path of the base directory.
    """
    baseDirectory = Path(args.output_base_directory)
    if baseDirectory.is_dir():
        return baseDirectory
    else:
        B2ERROR(f"{args.output_base_directory} is not an existing directory.")
        sys.exit(1)


def get_output_directory(args, sampleRegistry):
    """Construct the output directory for the JSON files based on the given base
    directory.

    Args:
        args (argparse.ArgumentParser): An argument parser assumed to have the
            attributes `output_base_directory` and `release`.
        sampleRegistry (dict): The input data/MC registry as a dict.

    Returns:
        outputDirectory (pathlib.Path): The directory to write the JSON files into.
    """
    baseDirectory = get_base_directory(args)
    DBGlobalTag = get_DBGlobalTag(args.release)
    beamEnergy = get_beam_energy_from_registry(sampleRegistry)

    return Path(baseDirectory, args.campaign, args.release, DBGlobalTag, beamEnergy)


def get_lpn_list(sampleInfo, mc):
    """Construct the list of LPNs of a set of samples in the sample registry.

    Args:
        sampleInfo (dict): Dict of the sample registry. Registry format is
            explained in documentation of `read_registry_yaml`.
        mc (bool): Are these JSON files being produced for MC skims?

    Returns:
        LPNList (list): List of LPNs to be used for this set of jobs.
    """
    if mc:
        # Allow looping over prod numbers
        if isinstance(sampleInfo["prodNumber"], list):
            prodNumbers = sampleInfo["prodNumber"]
        else:
            prodNumbers = [sampleInfo["prodNumber"]]

        # Allow prod and run numbers to just be numbers in YAML file (without prod00.. at start)
        # This will pad a number with the correct number of zeros, and add the correct letters at the front
        prodNumbers = [str(n) if str(n).startswith("prod00") else "prod" + str(n).zfill(8) for n in prodNumbers]

        # Similar for database global tag ID
        if not str(sampleInfo["inputDBGlobalTag"]).startswith("DB00"):
            sampleInfo["inputDBGlobalTag"] = "DB" + str(sampleInfo["inputDBGlobalTag"]).zfill(8)

        LPNList = [str(Path(sampleInfo["LPNPrefix"],
                            sampleInfo["inputReleaseNumber"],
                            sampleInfo["inputDBGlobalTag"],
                            sampleInfo["mcCampaign"],
                            prodNumber,
                            sampleInfo["experimentNumber"],
                            sampleInfo["beamEnergy"],
                            sampleInfo["runNumber"],
                            sampleInfo["mcType"],
                            sampleInfo["inputDataLevel"]))
                   for prodNumber in prodNumbers]
    else:
        if not str(sampleInfo["prodNumber"]).startswith("prod00"):
            sampleInfo["prodNumber"] = "prod" + str(sampleInfo["prodNumber"]).zfill(8)

        if not str(sampleInfo["inputDBGlobalTag"]).startswith("DB00"):
            sampleInfo["inputDBGlobalTag"] = "DB" + str(sampleInfo["inputDBGlobalTag"]).zfill(8)

        LPNList = [str(Path(sampleInfo["LPNPrefix"],
                            sampleInfo["inputReleaseNumber"],
                            sampleInfo["inputDBGlobalTag"],
                            sampleInfo["procNumber"],
                            sampleInfo["prodNumber"],
                            sampleInfo["experimentNumber"],
                            sampleInfo["beamEnergy"],
                            run,
                            sampleInfo["inputDataLevel"]))
                   for run in sampleInfo["runNumbers"]]

    return LPNList


@lru_cache()
def get_DBGlobalTag(releaseNumber):
    """Query the conditions database for the global tag to be used with a release.
    This function will look for global tags associated with all releases between
    the given release and the latest major release prior to it.

    * If only one global tag is used, then that is returned.

    * If more than one global tag is found, then the user ir prompted to select
      the one they want to use.

    * If no global tags are found, then an error is printed, and the script exits.

    Args:
        releaseNumber (str): The label of the release being used for the skims.

    Returns:
        DBGlobalTag (str): the database global tag, in the format DBxxxxxxxx.
    """
    # Check that the release number is of the correct form
    import re
    r = re.compile("^release(-[0-9]{2}){3}$")
    if not r.match(releaseNumber):
        B2ERROR("Release number must be of the form 'release-XX-XX-XX'.")
        sys.exit(1)

    initialReleaseNumber = releaseNumber

    _, majorNumber, minorNumber, patchNumber = releaseNumber.split('-')
    patchNumber = int(patchNumber)
    minorNumber = int(minorNumber)

    db = ConditionsDB()

    globalTags = []

    while minorNumber >= 0:
        releaseNumber = f"release-{majorNumber}-{str(minorNumber).zfill(2)}-{str(patchNumber).zfill(2)}"

        try:
            req = db.request("GET", f"/globalTag/{encode_name(releaseNumber)}")
            globalTagID = req.json()["globalTagId"]

            DBGlobalTag = "DB" + str(globalTagID).zfill(8)

            globalTags.append((DBGlobalTag, releaseNumber))

        except ConditionsDB.RequestError:
            # B2WARNING(f"Could not find global tag for {releaseNumber}.")
            pass

        if patchNumber == 0:
            # Decrease minor release number, set patch release number to 5
            # (can be set higher to check for more patch releases)
            minorNumber -= 1
            patchNumber = 5
        else:
            patchNumber -= 1

    if len(globalTags) == 1:
        # If only one available, use that
        DBGlobalTag, releaseNumber = globalTags[0]
        B2INFO(f"Using conditions database global tag {DBGlobalTag} for {releaseNumber}.")
        return DBGlobalTag

    elif len(globalTags) >= 1:
        # If multiple available, ask user what they want
        nGlobalTags = len(globalTags)
        B2INFO("Multiple conditions database global tags found.\n"
               f"Please select (one of 1--{nGlobalTags}).")
        for iGlobalTag, (DBGlobalTag, releaseNumber) in enumerate(globalTags):
            print(f"  [{iGlobalTag+1}] {releaseNumber}: {DBGlobalTag}")

        # Wait for user to select a global tag
        while True:
            selection = input()
            try:
                selection = int(selection) - 1
            except ValueError:
                pass

            if selection in range(nGlobalTags):
                break

        DBGlobalTag, releaseNumber = globalTags[selection]
        B2INFO(f"Using conditions database global tag {DBGlobalTag} for {releaseNumber}.")
        return DBGlobalTag

    else:
        # If none available, throw an error
        B2ERROR(f"Could not find any conditions database global tags for releases between\n"
                "release-{majorNumber}-{minorNumber}-00 and {initialReleaseNumber}.")
        sys.exit(1)


def get_HS06_per_event(skimStatsDict, skimName, sampleLabel):
    """Convert KEKCC CPU time into HEP-SPEC06 (the standard unit used for
    expressing CPU usage). According to
    `Confluence <https://confluence.desy.de/display/BI/Production+Definition>`_,
    the conversion factor is about 20.

    Args:
        skimStatsDict (dict): The skim stats read in from ``skimStats.json``.
        skimName (str): The name of the skim to retrieve the statistic for.
        sampleLabel (str): The label of the test sample to get the statistic for.

    Returns:
        HS06TimePerEvent (float): The converted time per event, now in units of HS06.
    """
    CPUTimePerEvent = skimStatsDict[skimName]["cpuTimePerEvent"][sampleLabel]
    HS06TimePerEvent = CPUTimePerEvent * 20
    return HS06TimePerEvent


def get_beam_energy_from_registry(sampleRegistry):
    """Read the input YAML file and retrieve the list of beam energies. Check
    for whether more than one beam energy is listed in the registry. Prints an
    error and exits if this is the case.

    Args:
        sampleRegistry (dict): The input data registry as a dict.

    Returns:
        beamEnergy (str): The beam energy as listed in the registry.
    """
    beamEnergies = [prod["beamEnergy"] for prod in sampleRegistry.values()]
    uniqueBeamEnergies = set(beamEnergies)

    if len(uniqueBeamEnergies) == 1:
        return list(uniqueBeamEnergies)[0]
    else:
        B2ERROR("More than one beam energy listed in input YAML file!")
        sys.exit(1)


def warn_local_script(args):
    """If a local script is given print a warning that a local script will be used.

    Args:
        args (argparse.ArgumentParser): An argparser expected to contain values
            `mc`,
    """
    if not args.local_skim_script:
        return

    if args.mc:
        dataOrMC = "MC"
    else:
        dataOrMC = "data"

    skimScript = args.local_skim_script
    if not skimScript.endswith('.py'):
        skimScript += '.py'

    localScriptDirectory = str(Path(dataOrMC, args.campaign, args.release, 'SkimScripts'))

    for skimName in args.skims:
        B2WARNING(f"Using local skim script! Please make sure to place sandbox file {skimScript}\n"
                  f"          in {Path(args.output_base_directory, localScriptDirectory).resolve()}\n"
                  f"          and modify {skimName}_Skim_Standalone.py to import this script.")


def make_request_dict(args, sampleRegistry, skimName, sampleLabel, prodNumber, LPNList):
    """Construct a dict for one skim and one set of data. Dict contains all the
    required fields for skim production.

    Args:
        args (argparse.ArgumentParser): An argparser expected to contain values
            for campaign name, starting prod number, and list of skims. Can also
            be any object which has these as attributes.
        sampleRegistry (dict): The input data registry as a dict.
        skimName (str): The name of the combined group of skims (*e.g.* feiSLCombined, BtoCharm).
        sampleLabel (str): Label in the registry for group of data in this job.
        prodNumber (int): Number to label this production request.
        LPNList (list): List of LPNs to include in the JSON file.

    Returns:
        skimRequestDict (dict): A dict ready to be saved as a JSON file.
    """
    sampleInfo = sampleRegistry[sampleLabel]
    statsSampleLabel = sampleInfo["sampleLabel"]  # Get label used by `b2skim-stats-print`

    skimStatsDict = get_skim_stats_dict()
    verify_stats_dict(args, sampleRegistry, skimStatsDict)

    individualSkims = combinedSkimsInfo[skimName]

    args.campaign = args.campaign

    if args.mc:
        dataOrMC = "MC"
        fabricationType = "MCSkim"
        LPNPrefix = "/belle/MC/skim"
    else:
        dataOrMC = "data"
        fabricationType = "DataSkim"
        LPNPrefix = "/belle/Data/skim"

    skimRequestDict = {
        "FabricationType": fabricationType,
        "ProductionName": f"{args.campaign}_{prodNumber}",
        "ProductionGroup": "skim",
        "Description": f"{args.campaign} skim campaign. {skimName} combined skim on {sampleLabel} {dataOrMC}.",
        "Release": args.release,
        "DBGlobalTag": get_DBGlobalTag(args.release),
        "Campaign": args.campaign,
        "BeamEnergy": get_beam_energy_from_registry(sampleRegistry),
        "TargetFileSize": 1024,
        "ExpectedEventCPUTime": get_HS06_per_event(skimStatsDict, skimName, statsSampleLabel),
        "ExpectedEventSize": skimStatsDict[skimName]["udstSizePerSkimmedEvent"][statsSampleLabel],
        "InputSandboxFilePrefix": f"{dataOrMC}/{args.campaign}/{args.release}/SkimScripts",
        "InputData": LPNList,
        "Priority": 8,
        "SteeringFile": f"{skimName}_Skim_Standalone.py",
        "SteeringFilePrefix": f"{dataOrMC}/{args.campaign}/{args.release}/SkimScripts",
        "LPNPrefix": LPNPrefix,
        "DataDescription": [
            {"SkimDecayMode": encodeSkimName(individualSkim),
             "DataLevel": "udst"} for individualSkim in individualSkims
        ]
    }

    # We only want the MCEventType to include the beam background level if the sample is BGx0
    if args.mc:
        if sampleInfo["mcBackground"] == "BGx0":
            skimRequestDict["MCEventType"] = sampleInfo["mcType"] + sampleInfo["mcBackground"]
        else:
            skimRequestDict["MCEventType"] = sampleInfo["mcType"]

    if args.local_skim_script:
        # Read in the name of the local skim module from the arguments
        skimScript = args.local_skim_script
        if not skimScript.endswith('.py'):
            skimScript += '.py'

        localScriptDirectory = str(Path(dataOrMC, args.campaign, args.release, 'SkimScripts'))
        skimRequestDict["InputSandboxFile"] = [skimScript]
        skimRequestDict["InputSandboxFilePrefix"] = localScriptDirectory

    return skimRequestDict


def write_json_files(sampleRegistry, args, outputDirectory):
    """Generate the dicts for each skim and registry entry, and write each to its own JSON file.

    Args:
        sampleRegistry (dict): The input data registry as a dict.
        args (argparse.ArgumentParser): An argparser expected to contain values
            for campaign name, starting prod number, and list of skims.
        outputDirectory (pathlib.Path, str): The location to save the JSON files.

    Returns:
        finalProdNumber (int): The greatest prod number used in the JSON files.
    """
    prodNumber = args.starting_prod_number - 1

    if args.one_lpn_per_json:
        B2INFO("Producing JSON files with one LPN per JSON file.")

    for skimName in args.skims:
        for sampleLabel, sampleInfo in sampleRegistry.items():

            SampleLPNList = get_lpn_list(sampleInfo, args.mc)

            # Make a list of LPN lists so that we can optionally have only LPN per JSON file
            if args.one_lpn_per_json:
                LPNLists = [[LPN] for LPN in SampleLPNList]
            else:
                LPNLists = [SampleLPNList]

            # MC campaign number is likely already in skim campaign name, so don't include it in sample label
            if args.mc:
                sampleLabelForFilename = sampleInfo["mcType"] + sampleInfo["mcBackground"]
            else:
                sampleLabelForFilename = sampleLabel

            for LPNList in LPNLists:
                prodNumber += 1
                skimRequestDict = make_request_dict(args, sampleRegistry, skimName, sampleLabel, prodNumber, LPNList)

                outputFileName = Path(outputDirectory, f"{args.campaign}_{prodNumber}_{skimName}_{sampleLabelForFilename}.json")
                if outputFileName.exists():
                    B2WARNING(f"Overwriting {outputFileName}")
                with open(outputFileName, "w") as outputFile:
                    json.dump(skimRequestDict, outputFile, indent=4)

        B2INFO(f"Make sure to copy {skimName}_Skim_Standalone.py to "
               f"{get_base_directory(args)}/{args.campaign}/{args.release}/SkimScripts/")

    return prodNumber


def get_argument_parser():
    """Define the argument parser.

    Returns:
        parser (argparse.ArgumentParser): A parser which defines the skim
            campaign, release number, and starting prod number.
    """
    description, epilog = __doc__.split('--epilog--')
    parser = argparse.ArgumentParser(
        description=description,
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=epilog
    )

    parser.add_argument("sampleRegistryYaml",
                        help="YAML file defining the samples produce JSON files for.")
    parser.add_argument("-s", "--skims", required=True, nargs="+",
                        metavar="SKIM", choices=combinedSkimsInfo.keys(),
                        help="List of skims to produce request files for. "
                        "Only accepts combined skims listed in `skim.registry.combined_skims`.")
    parser.add_argument("-n", "--starting-prod-number", required=True, type=int,
                        help="Starting prod number of the JSON files.")
    parser.add_argument("-o", "--output-base-directory", required=True,
                        help="Base directory for output. "
                        "This should be the base directory of the ``B2P/MC`` or ``B2P/data`` repo.")
    parser.add_argument("-c", "--campaign", required=True,
                        help="Name of the campaign, *e.g.* SKIMDATAx1.")
    parser.add_argument("-r", "--release", required=True,
                        help="The basf2 to release to be used, *e.g.* release-04-00-03.")
    parser.add_argument("-l", "--local-skim-script",
                        help="File name of the local skim script to use, if any. *e.g.* ``ewp_local.py``. "
                        "Should not include any path before the file name.")
    parser.add_argument("-1", "--one-lpn-per-json", action="store_true",
                        help="Only include one LPN in each JSON file.")

    mcDataGroup = parser.add_mutually_exclusive_group(required=True)
    mcDataGroup.add_argument('--mc', '--MC', action='store_true',
                             help='Produce JSON files for MC.')
    mcDataGroup.add_argument('--data', '--Data', action='store_true',
                             help='Produce JSON files for data.')

    return parser


def main():
    """Reads in the YAML file, and creates the JSON files."""
    parser = get_argument_parser()
    args = parser.parse_args()

    sampleRegistry = read_registry_yaml(args.sampleRegistryYaml, args.mc)

    outputDirectory = get_output_directory(args, sampleRegistry)
    outputDirectory.mkdir(parents=True, exist_ok=True)

    finalProdNumber = write_json_files(sampleRegistry, args, outputDirectory)

    warn_local_script(args)
    B2INFO(f"Successfully generated {', '.join(args.skims)} JSON files for {', '.join(sampleRegistry.keys())} samples.")
    B2INFO(f"The JSON files were saved to {outputDirectory}")
    B2INFO(f"The prod numbers of these files range from {args.starting_prod_number} to {finalProdNumber}.")


if __name__ == "__main__":
    main()
