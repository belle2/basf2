#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""\
.. Note::
   This tool is intended for use by skim production managers, not by skim liaisons.

``%(prog)s`` is a tool for producing grid production requests in the format required by the
`production system <https://confluence.desy.de/display/BI/Production+Definition>`_.

YAML files are used by this tool to define the LPNs of datasets. Below are examples of valid YAML
entries for data and MC.

.. code-block:: yaml

    ## Example of a YAML file for data:
    proc9_exp3r1:
        sampleLabel: proc9_exp3
        LPNPrefix: /belle/Data
        inputReleaseNumber: release-03-02-02
        prodNumber: prod00008530
        inputDBGlobalTag: DB00000654
        procNumber: proc9
        experimentNumber: e0003
        beamEnergy: 4S
        inputDataLevel: mdst
        runNumbers:
            - r02724
            - r02801
            - r02802

    proc9_exp3r2:
        sampleLabel: proc9_exp3
        LPNPrefix: /belle/Data
        inputReleaseNumber: release-03-02-02
        # prodNumber, inputDBGlobalTag, experimentNumber, and runNumbers can be integers
        prodNumber: 8530
        inputDBGlobalTag: 654
        procNumber: proc9
        experimentNumber: 3
        beamEnergy: 4S
        inputDataLevel: mdst
        runNumbers:
            - 3237
            - 3238
            - 3239


    ## Example of a YAML file for MC:
    MC12b_mixed:
        sampleLabel: MC12_mixedBGx1
        LPNPrefix: /belle/MC
        inputReleaseNumber: release-03-01-00
        inputDBGlobalTag: DB00000547
        mcCampaign: MC12b
        prodNumber: prod00007392
        experimentNumber: s00/e1003
        beamEnergy: 4S
        mcType: mixed
        mcBackground: BGx1
        inputDataLevel: mdst
        runNumber: r00000

    MC12b_charged:
        sampleLabel: MC12_chargedBGx1
        LPNPrefix: /belle/MC
        inputReleaseNumber: release-03-01-00
        # inputDBGlobalTag, prodNumber, and runNumber can be integers
        inputDBGlobalTag: 547
        mcCampaign: MC12b
        prodNumber:
            - 7799  # prodNumber can be a list
            - 7802
        experimentNumber: s00/e1003
        beamEnergy: 4S
        mcType: charged
        mcBackground: BGx1
        inputDataLevel: mdst
        runNumber: 0

To produce JSON files for a list of combined skims, pass this tool the YAML file and the
names of the skims. The combined skims must be defined in
`skim.registry.combined_skims`. The other required arguments include the skim campaign,
intended release to be used, and base directory of the repository to output the JSON
files in.

This tool is designed to work with the ``skimStats.json`` output of
``b2skim-stats-print`` (see :ref:`testing-skims`). The YAML files can be used to specify
which sample statistics are to be used for each dataset, with the keyword
``sampleLabel``---this must match one of the sample labels used by the skim statistics
tools. ``skimStats.json`` must be present in the current directory when this tool is
run.

--epilog--
.. rubric:: Example usage

* Produce requests for EWP and feiSLCombined skims on proc9::

    $ %(prog)s Registry_proc9.yaml -s EWP feiSLCombined --data -n 101 -c SKIMDATAx1 -r release-04-01-01 -o B2P/data/

* Produce requests for EWP on MC13, with one LPN per JSON file::

    $ %(prog)s Registry_MC13.yaml -1 -s EWP --data -n 101 -c SKIMDATAx1 -r release-04-01-01 -o B2P/data/

* Produce requests for EWP on MC13, using local skim module script::

    $ %(prog)s Registry_MC13.yaml -l ewp_local.py -s EWP --data -n 101 -c SKIMDATAx1 -r release-04-01-01 -o B2P/data/
"""

__author__ = "Phil Grace, Racha Cheaib"
__email__ = "philip.grace@adelaide.edu.au, rachac@mail.ubc.ca"


import argparse
from functools import lru_cache
from itertools import product
import json
from pathlib import Path
import re
import sys
import yaml

from basf2 import B2ERROR, B2INFO, B2WARNING
from conditions_db import ConditionsDB, encode_name
from skimExpertFunctions import encodeSkimName
from skim.registry import combined_skims as combinedSkimsInfo


def read_registry_yaml(sampleRegistryYaml, mc):
    """Load in the YAML file as a dict. Checks that all expected values
    present before proceeding.

    Args:
        sampleRegistryYaml (str): Location of the registry YAML file to read in.
        mc (bool): Are these JSON files being produced for MC skims?

    Returns:
        sampleRegistry (dict): The input data/MC registry as a dict.

    .. note::

        The YAML file needs to contain certain values for this to work. The
        top-level names are used throughout this script as labels for each set
        of data/MC. The key "sampleLabel" must correspond to a sample label used
        in `b2skim-stats-print`, so that the performance statistics can be
        retrieved from ``skimStats.json``. The remaining keys are used to
        construct the LPNs of the input datasets.
    """
    with open(sampleRegistryYaml) as sampleRegistryFile:
        sampleRegistry = yaml.safe_load(sampleRegistryFile)

    verify_registry(sampleRegistry, mc)

    return sampleRegistry


def get_skim_stats_dict():
    """Read in the JSON output of ``b2skim-stats-print`` into a dict.

    Returns:
        skimStatsDict (dict): A dict containing the tested skim statistics.
    """
    # Assumes that skimStats.json is in the current directory
    try:
        with open("skimStats.json") as skimStatsFile:
            skimStatsDict = json.load(skimStatsFile)
    except FileNotFoundError:
        B2ERROR(
            "Could not find required file `skimStats.json` in current directory.\n"
            "          Please run `b2skim-stats-print` with the `-J` flag, and put\n"
            "          the output `skimStats.json` in the current directory."
        )
        sys.exit(1)

    return skimStatsDict


def verify_registry(sampleRegistry, mc):
    """Check that the registry contains all the values that are expected. If a
    value is missing, print an error and exit.

    Args:
        sampleRegistry (dict): The input data/MC registry as a dict.
        mc (bool): Are these JSON files being produced for MC skims?
    """
    expectedMCEntries = [
        "sampleLabel",
        "LPNPrefix",
        "inputReleaseNumber",
        "inputDBGlobalTag",
        "mcCampaign",
        "prodNumber",
        "experimentNumber",
        "beamEnergy",
        "inputDataLevel",
        "mcType",
        "mcBackground",
        "runNumber",
    ]
    expectedDataEntries = [
        "LPNPrefix",
        "inputReleaseNumber",
        "inputDBGlobalTag",
        "procNumber",
        "prodNumber",
        "experimentNumber",
        "beamEnergy",
        "inputDataLevel",
        "runNumbers",
    ]

    missingEntries = []
    if mc:
        missingEntries = [
            (sampleLabel, expectedEntry)
            for (sampleLabel, sampleInfo) in sampleRegistry.items()
            for expectedEntry in expectedMCEntries
            if expectedEntry not in sampleInfo.keys()
        ]
    else:
        missingEntries = [
            (sampleLabel, expectedEntry)
            for (sampleLabel, sampleInfo) in sampleRegistry.items()
            for expectedEntry in expectedDataEntries
            if expectedEntry not in sampleInfo.keys()
        ]

    if missingEntries:
        for sampleLabel, missingEntry in missingEntries:
            B2ERROR(f"Missing entry {missingEntry} for registry entry {sampleLabel}.")
        sys.exit(1)


def verify_stats_dict(args, sampleRegistry, skimStatsDict):
    """Verify that the required statistics are present in the stats dict. If any
    issues are found, print an error and exit.

    Args:
        args (argparse.ArgumentParser): An argparser expected to contain values for
            campaign name and list of skims. Can also be any object which has these as
            attributes.
        sampleRegistry (dict): The input data/MC registry as a dict.
        skimStatsDict (dict): A dict containing the tested skim statistics.
    """
    skims = args.skims
    statistics = ["cpuTimePerEvent", "udstSizePerSkimmedEvent"]
    sampleLabels = [sampleInfo["sampleLabel"] for sampleInfo in sampleRegistry.values()]

    # Verify that all the requested skims have statistics listed
    missingSkims = [skim for skim in skims if skim not in skimStatsDict.keys()]
    if missingSkims:
        for missingSkim in missingSkims:
            B2ERROR(
                f"Cannot find stats for {missingSkim} skim in skimStats.json.\n"
                "          Perhaps you misspelled it or forgot to produce the\n"
                "          stats with `b2skim-stats-print`?"
            )
        sys.exit(1)

    # Verify that all the requested samples were tested, and returned non-None values
    for skim, statistic, sampleLabel in product(skims, statistics, sampleLabels):
        try:
            statValue = skimStatsDict[skim][statistic][sampleLabel]
            if statValue is None:
                B2ERROR(
                    f"The value for {statistic} for {skim} skim on {sampleLabel} sample"
                    "is `None`! This value is required for the produced JSON files."
                )
                sys.exit(1)
        except KeyError:
            B2ERROR(
                f"Missing value for {statistic} for {skim} skim on {sampleLabel} "
                "sample. Perhaps you misspelled it or forgot to produce the stats "
                "with `b2skim-stats-print`."
            )
            sys.exit(1)


def get_base_directory(args):
    """Read the output base directory from the argparse arguments, and return
    that location as a `pathlib.Path` object. Checks that the given directory
    exists, and will print an error and exits if it is not.

    Args:
        args (argparse.ArgumentParser): An argument parser assumed to have the
            attribute `output_base_directory`.

    Returns:
        baseDirectory (pathlib.Path): The path of the base directory.
    """
    baseDirectory = Path(args.output_base_directory)
    if baseDirectory.is_dir():
        return baseDirectory
    else:
        B2ERROR(f"{args.output_base_directory} is not an existing directory.")
        sys.exit(1)


def get_output_directory(args, sampleRegistry):
    """Construct the output directory for the JSON files based on the given base
    directory.

    Args:
        args (argparse.ArgumentParser): An argument parser assumed to have the
            attributes `output_base_directory` and `release`.
        sampleRegistry (dict): The input data/MC registry as a dict.

    Returns:
        outputDirectory (pathlib.Path): The directory to write the JSON files into.
    """
    baseDirectory = get_base_directory(args)
    DBGlobalTag = get_DBGlobalTag(args.release)
    beamEnergy = get_beam_energy_from_registry(sampleRegistry)

    return Path(baseDirectory, args.campaign, args.release, DBGlobalTag, beamEnergy)


def get_lpn_list(sampleInfo, mc):
    """Construct the list of LPNs of a set of samples in the sample registry.

    Args:
        sampleInfo (dict): Dict of the sample registry. Registry format is
            explained in documentation of `read_registry_yaml`.
        mc (bool): Are these JSON files being produced for MC skims?

    Returns:
        LPNList (list): List of LPNs to be used for this set of jobs.
    """
    if mc:
        # Allow looping over prod numbers
        if isinstance(sampleInfo["prodNumber"], list):
            prodNumbers = sampleInfo["prodNumber"]
        else:
            prodNumbers = [sampleInfo["prodNumber"]]

        # Allow prod numbers, run number and database global tag ID to just be
        # numbers in YAML file (without *e.g.* prod0000 at start). This will pad each
        # number with the correct number of zeros, and add the correct letters at the
        # front.

        # Allow prod numbers, run numbers and database global tag ID to just be numbers
        # in YAML file (without *e.g.* prod00.. at start). This will pad a number with
        # the correct number of zeros, and add the correct letters at the front.
        prodNumbers = [
            str(n) if str(n).startswith("prod") else "prod" + str(n).zfill(8)
            for n in prodNumbers
        ]

        if not str(sampleInfo["inputDBGlobalTag"]).startswith("DB"):
            sampleInfo["inputDBGlobalTag"] = "DB" + str(
                sampleInfo["inputDBGlobalTag"]
            ).zfill(8)

        if not str(sampleInfo["runNumber"]).startswith("r"):
            sampleInfo["runNumber"] = "r" + str(sampleInfo["runNumber"]).zfill(5)

        LPNList = [
            str(
                Path(
                    sampleInfo["LPNPrefix"],
                    sampleInfo["inputReleaseNumber"],
                    sampleInfo["inputDBGlobalTag"],
                    sampleInfo["mcCampaign"],
                    prodNumber,
                    sampleInfo["experimentNumber"],
                    sampleInfo["beamEnergy"],
                    sampleInfo["runNumber"],
                    sampleInfo["mcType"],
                    sampleInfo["inputDataLevel"],
                )
            )
            for prodNumber in prodNumbers
        ]
    else:
        # Allow prod number, experiment number, run numbers and database global tag ID
        # to just be numbers in YAML file (without *e.g.* prod0000 at start). This will
        # pad each number with the correct number of zeros, and add the correct letters
        # at the front.
        if not str(sampleInfo["prodNumber"]).startswith("prod"):
            sampleInfo["prodNumber"] = "prod" + str(sampleInfo["prodNumber"]).zfill(8)

        if not str(sampleInfo["inputDBGlobalTag"]).startswith("DB"):
            sampleInfo["inputDBGlobalTag"] = "DB" + str(
                sampleInfo["inputDBGlobalTag"]
            ).zfill(8)

        if not str(sampleInfo["experimentNumber"]).startswith("e"):
            sampleInfo["experimentNumber"] = "e" + str(
                sampleInfo["experimentNumber"]
            ).zfill(4)

        sampleInfo["runNumbers"] = [
            str(n) if str(n).startswith("r") else "r" + str(n).zfill(5)
            for n in sampleInfo["runNumbers"]
        ]

        LPNList = [
            str(
                Path(
                    sampleInfo["LPNPrefix"],
                    sampleInfo["inputReleaseNumber"],
                    sampleInfo["inputDBGlobalTag"],
                    sampleInfo["procNumber"],
                    sampleInfo["prodNumber"],
                    sampleInfo["experimentNumber"],
                    sampleInfo["beamEnergy"],
                    run,
                    sampleInfo["inputDataLevel"],
                )
            )
            for run in sampleInfo["runNumbers"]
        ]

    return LPNList


@lru_cache()
def get_DBGlobalTag(releaseNumber):
    """Query the conditions database for the global tag to be used with a release.
    This function will look for global tags associated with all releases between
    the given release and the latest major release prior to it.

    * If only one global tag is used, then that is returned.

    * If more than one global tag is found, then the user ir prompted to select
      the one they want to use.

    * If no global tags are found, then an error is printed, and the script exits.

    Args:
        releaseNumber (str): The label of the release being used for the skims.

    Returns:
        DBGlobalTag (str): the database global tag, in the format DBxxxxxxxx.
    """
    r = re.compile("^release(-[0-9]{2}){3}$")
    if not r.match(releaseNumber):
        B2ERROR("Release number must be of the form 'release-XX-XX-XX'.")
        sys.exit(1)

    initialReleaseNumber = releaseNumber  # noqa F841

    _, majorNumber, minorNumber, patchNumber = releaseNumber.split("-")
    patchNumber = int(patchNumber)
    minorNumber = int(minorNumber)

    db = ConditionsDB()

    globalTags = []

    while minorNumber >= 0:
        releaseNumber = (
            f"release-{majorNumber}-{str(minorNumber).zfill(2)}-"
            f"{str(patchNumber).zfill(2)}"
        )

        try:
            req = db.request("GET", f"/globalTag/{encode_name(releaseNumber)}")
            globalTagID = req.json()["globalTagId"]

            DBGlobalTag = "DB" + str(globalTagID).zfill(8)

            globalTags.append((DBGlobalTag, releaseNumber))

        except ConditionsDB.RequestError:
            # B2WARNING(f"Could not find global tag for {releaseNumber}.")
            pass

        if patchNumber == 0:
            # Decrease minor release number, set patch release number to 5
            # (can be set higher to check for more patch releases)
            minorNumber -= 1
            patchNumber = 5
        else:
            patchNumber -= 1

    if len(globalTags) == 1:
        # If only one available, use that
        DBGlobalTag, releaseNumber = globalTags[0]
        B2INFO(
            f"Using conditions database global tag {DBGlobalTag} for {releaseNumber}."
        )
        return DBGlobalTag

    elif len(globalTags) >= 1:
        # If multiple available, ask user what they want
        nGlobalTags = len(globalTags)
        B2INFO(
            "Multiple conditions database global tags found.\n"
            f"Please select (one of 1--{nGlobalTags})."
        )
        for iGlobalTag, (DBGlobalTag, releaseNumber) in enumerate(globalTags):
            print(f"  [{iGlobalTag+1}] {releaseNumber}: {DBGlobalTag}")

        # Wait for user to select a global tag
        while True:
            selection = input()
            try:
                selection = int(selection) - 1
            except ValueError:
                pass

            if selection in range(nGlobalTags):
                break

        DBGlobalTag, releaseNumber = globalTags[selection]
        B2INFO(
            f"Using conditions database global tag {DBGlobalTag} for {releaseNumber}."
        )
        return DBGlobalTag

    else:
        # If none available, throw an error
        B2ERROR(
            f"Could not find any conditions database global tags for releases between\n"
            "release-{majorNumber}-{minorNumber}-00 and {initialReleaseNumber}."
        )
        sys.exit(1)


def get_beam_energy_from_registry(sampleRegistry):
    """Read the input YAML file and retrieve the list of beam energies. Check
    for whether more than one beam energy is listed in the registry. Prints an
    error and exits if this is the case.

    Args:
        sampleRegistry (dict): The input data registry as a dict.

    Returns:
        beamEnergy (str): The beam energy as listed in the registry.
    """
    beamEnergies = [prod["beamEnergy"] for prod in sampleRegistry.values()]
    uniqueBeamEnergies = set(beamEnergies)

    if len(uniqueBeamEnergies) == 1:
        return list(uniqueBeamEnergies)[0]
    else:
        B2ERROR("More than one beam energy listed in input YAML file!")
        sys.exit(1)


def strip_campaign(label):
    """Remove anything that looks like an MC campaign from the beginning of a label.
    This function could be extended to also strip "procX" or "bucketY" from labels.

    Args:
        label (str): A sample label.

    Returns:
        labelWithoutCampaign (str): The same sample label, but without the MC campaign
            at the beginning.
    """
    # This regex makes the following replacements:
    #   MC13a_ccbar --> ccbar
    #   M13_ccbar   --> ccbar
    #   M13b_ccbar  --> ccbar
    #   MC12ccbar   --> ccbar
    #   MC11accbar  --> accbar (will not remove the 'a' in this case)
    MCCampaignRegex = r"^MC?[0-9]{2}(_|[a-z]_)?"
    return re.sub(MCCampaignRegex, "", label)


def warn_local_script(args):
    """If a local script is given print a warning that a local script will be used.

    Args:
        args (argparse.ArgumentParser): An argparser expected to contain values
            `mc`,
    """
    if not args.local_skim_script:
        return

    if args.mc:
        dataOrMC = "MC"
    else:
        dataOrMC = "data"

    skimScript = args.local_skim_script
    if not skimScript.endswith(".py"):
        skimScript += ".py"

    localScriptDirectory = str(
        Path(dataOrMC, args.campaign, args.release, "SkimScripts")
    )

    for skimName in args.skims:
        B2WARNING(
            f"Using local skim script! Please make sure to place sandbox file {skimScript}\n"
            f"          in {Path(args.output_base_directory, localScriptDirectory).resolve()}\n"
            f"          and modify {skimName}_Skim_Standalone.py to import this script."
        )


def make_request_dict(
    args, sampleRegistry, skimName, sampleLabel, LPNList, LPNBlockIdentifier=None,
):
    """Construct a dict for one skim and one set of data. Dict contains all the
    required fields for skim production.

    Args:
        args (argparse.ArgumentParser): An argparser expected to contain values for
            campaign name and list of skims. Can also be any object which has these as
            attributes.
        sampleRegistry (dict): The input data registry as a dict.
        skimName (str): The name of the combined group of skims (*e.g.* feiSLCombined, BtoCharm).
        sampleLabel (str): Label in the registry for group of data in this job.
        LPNList (list): List of LPNs to include in the JSON file.
        LPNBlockIdentifier (str): Extra identifier to be appended to filenames and prod
            names to make sure they are unique.

    Returns:
        skimRequestDict (dict): A dict ready to be saved as a JSON file.
    """
    sampleInfo = sampleRegistry[sampleLabel]
    # Get label used by `b2skim-stats-print`
    statsSampleLabel = sampleInfo["sampleLabel"]

    # Append the identifier if we need to
    if LPNBlockIdentifier:
        sampleLabel += LPNBlockIdentifier

    skimStatsDict = get_skim_stats_dict()
    verify_stats_dict(args, sampleRegistry, skimStatsDict)

    individualSkims = combinedSkimsInfo[skimName]

    if args.mc:
        fabricationType = "MCSkim"
        LPNPrefix = "/belle/MC"
    else:
        fabricationType = "DataSkim"
        LPNPrefix = "/belle/Data"

    skimRequestDict = {
        "FabricationType": fabricationType,
        "ProductionName": f"{args.campaign}_{skimName}_{strip_campaign(sampleLabel)}",
        "ProductionGroup": "skim",
        "Description": f"{args.campaign} {skimName} skim on {sampleLabel}.",
        "Release": args.release,
        "DBGlobalTag": get_DBGlobalTag(args.release),
        "Campaign": args.campaign,
        "BeamEnergy": get_beam_energy_from_registry(sampleRegistry),
        "TargetFileSize": 1024,
        "ExpectedEventCPUTime": (
            skimStatsDict[skimName]["HS06TimePerEvent"][statsSampleLabel]
        ),
        "ExpectedEventSize": (
            skimStatsDict[skimName]["udstSizePerInputEvent"][statsSampleLabel]
        ),
        "InputSandboxFilePrefix": f"{args.campaign}/{args.release}/SkimScripts",
        "InputData": LPNList,
        "Priority": 8,
        "SteeringFile": f"{skimName}_Skim_Standalone.py",
        "SteeringFilePrefix": f"{args.campaign}/{args.release}/SkimScripts",
        "LPNPrefix": LPNPrefix,
        "DataDescription": [
            {"SkimDecayMode": encodeSkimName(individualSkim), "DataLevel": "udst"}
            for individualSkim in individualSkims
        ],
    }

    # We only want the MCEventType to include the beam background level if the sample is BGx0
    if args.mc:
        skimRequestDict["MCEventType"] = sampleInfo["mcType"].rstrip("BGx1")

    if args.local_skim_script:
        # Read in the name of the local skim module from the arguments
        skimScript = args.local_skim_script
        if not skimScript.endswith(".py"):
            skimScript += ".py"

        localScriptDirectory = str(Path(args.campaign, args.release, "SkimScripts"))
        skimRequestDict["InputSandboxFile"] = [skimScript]
        skimRequestDict["InputSandboxFilePrefix"] = localScriptDirectory

    return skimRequestDict


def write_json_files(sampleRegistry, args, outputDirectory):
    """Generate the dicts for each skim and registry entry, and write each to its own JSON file.

    Args:
        sampleRegistry (dict): The input data registry as a dict.
        args (argparse.ArgumentParser): An argparser expected to contain values for
            campaign name and list of skims.
        outputDirectory (pathlib.Path, str): The location to save the JSON files.
    """

    if args.one_lpn_per_json:
        B2INFO("Producing JSON files with one LPN per JSON file.")

    for skimName in args.skims:
        for sampleLabel, sampleInfo in sampleRegistry.items():

            SampleLPNList = get_lpn_list(sampleInfo, args.mc)

            # Make a list of LPN lists so that we can optionally have only LPN per JSON file
            if args.one_lpn_per_json:
                LPNLists = [[LPN] for LPN in SampleLPNList]
            else:
                LPNLists = [SampleLPNList]

            # MC campaign number is likely already in skim campaign name, so don't include it in sample label
            sampleLabelForFilename = strip_campaign(sampleLabel)

            for LPNBlockNumber, LPNList in enumerate(LPNLists):

                # If we have broken up the LPNs into one-per-file, then we need to add some more
                # letters and numbers to keep our prod names and filenames unique
                if args.one_lpn_per_json:
                    LPNBlockIdentifier = f"_b{LPNBlockNumber + 1}"
                    outputFileName = f"{args.campaign}_{skimName}_{sampleLabelForFilename}{LPNBlockIdentifier}.json"
                else:
                    LPNBlockIdentifier = ""
                    outputFileName = (
                        f"{args.campaign}_{skimName}_{sampleLabelForFilename}.json"
                    )

                outputFilePath = Path(outputDirectory, outputFileName)

                skimRequestDict = make_request_dict(
                    args,
                    sampleRegistry,
                    skimName,
                    sampleLabel,
                    LPNList,
                    LPNBlockIdentifier,
                )

                if outputFilePath.exists():
                    B2WARNING(f"Overwriting {outputFilePath}")
                with open(outputFilePath, "w") as outputFile:
                    json.dump(skimRequestDict, outputFile, indent=4)

        B2INFO(
            f"Make sure to copy {skimName}_Skim_Standalone.py to "
            f"{get_base_directory(args)}/{args.campaign}/{args.release}/SkimScripts/"
        )


def get_argument_parser():
    """Define the argument parser.

    Returns:
        parser (argparse.ArgumentParser): A parser which defines the skim
            campaign, release number, and starting prod number.
    """
    description, epilog = __doc__.split("--epilog--")
    parser = argparse.ArgumentParser(
        description=description,
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=epilog,
    )

    parser.add_argument(
        "sampleRegistryYaml",
        help="YAML file defining the samples produce JSON files for.",
    )
    parser.add_argument(
        "-s",
        "--skims",
        required=True,
        nargs="+",
        metavar="SKIM",
        choices=combinedSkimsInfo.keys(),
        help="List of skims to produce request files for. "
        "Only accepts combined skims listed in `skim.registry.combined_skims`.",
    )
    parser.add_argument(
        "-o",
        "--output-base-directory",
        required=True,
        help="Base directory for output. "
        "This should be the base directory of the ``B2P/MC`` or ``B2P/data`` repo.",
    )
    parser.add_argument(
        "-c",
        "--campaign",
        required=True,
        help="Name of the campaign, *e.g.* SKIMDATAx1.",
    )
    parser.add_argument(
        "-r",
        "--release",
        required=True,
        help="The basf2 to release to be used, *e.g.* release-04-00-03.",
    )
    parser.add_argument(
        "-l",
        "--local-skim-script",
        help="File name of the local skim script to use, if any. *e.g.* ``ewp_local.py``. "
        "Should not include any path before the file name.",
    )
    parser.add_argument(
        "-1",
        "--one-lpn-per-json",
        action="store_true",
        help="Only include one LPN in each JSON file.",
    )

    mcDataGroup = parser.add_mutually_exclusive_group(required=True)
    mcDataGroup.add_argument(
        "--mc", "--MC", action="store_true", help="Produce JSON files for MC."
    )
    mcDataGroup.add_argument(
        "--data", "--Data", action="store_true", help="Produce JSON files for data."
    )

    return parser


def main():
    """Reads in the YAML file, and creates the JSON files."""
    parser = get_argument_parser()
    args = parser.parse_args()

    sampleRegistry = read_registry_yaml(args.sampleRegistryYaml, args.mc)

    outputDirectory = get_output_directory(args, sampleRegistry)
    outputDirectory.mkdir(parents=True, exist_ok=True)

    write_json_files(sampleRegistry, args, outputDirectory)

    warn_local_script(args)
    B2INFO(
        f"Successfully generated {', '.join(args.skims)} JSON files for "
        f"{', '.join(sampleRegistry.keys())} samples."
    )
    B2INFO(f"The JSON files were saved to {outputDirectory}")


if __name__ == "__main__":
    main()
