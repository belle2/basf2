#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Prepares the JSON request files for grid production of skims. See
`Confluence <https://confluence.desy.de/display/BI/Production+Definition>`_
for an explanation of the production system.

Important! This tool requires that you have done the following:
 * Run `b2setup` so that the skim expert functions can be used, and
 * Source the file `setup.sh` in the main directory of this repository, so that
   the combined skim info in the data prod repository can be accessed.

To run this script, first produce the skim stats for the combined skims using
`b2skim-stats-submit` and `b2skim-stats-print` (the latter with the flag ``-J``
to produce a JSON file). Put the output JSON file ``skimStats.json`` in the
current directory.

The input LPN lists are constructed from the YAML files. Examples for MC and data
are given in the docstring of `read_registry_yaml` below.

Example usage:
    b2skim-prod-json RunRegistry_proc9.yaml --data -s LeptonicUntagged -n 9001 -c SKIMDATAx1 -r release-04-01-01 -o B2P/data/

Example usage for local skim script:
    b2skim-prod-json RunRegistry_proc9.yaml --data -s LeptonicUntagged -n 9001 -c SKIMDATAx1 -r release-04-01-01 -o B2P/data/ -l leptonic.py
"""

__author__ = "Phil Grace, Racha Cheaib"
__email__ = "philip.grace@adelaide.edu.au, rachac@mail.ubc.ca"


import argparse
from functools import lru_cache
from itertools import product
import json
from pathlib import Path
import sys
import yaml

from basf2 import B2ERROR, B2INFO, B2WARNING
from conditions_db import ConditionsDB, encode_name
from ROOT import PyConfig
# Importing ROOT in skimExpertFunctions has the side-effect of hijacking argument parsing
PyConfig.IgnoreCommandLineOptions = True
from skimExpertFunctions import encodeSkimName

try:
    from skimprod.skiminfo import combinedSkimsInfo
except ModuleNotFoundError:
    B2ERROR("Please source `setup.sh` in the data prod repository and try again.")
    sys.exit(1)


def read_registry_yaml(sampleRegistryYaml, mc):
    """Load in the YAML file as a dict. Checks that all expected values
    present before proceeding.

    Args:
        sampleRegistryYaml (str): Location of the registry YAML file to read in.
        mc (bool): Are these JSON files being produced for MC skims?

    Returns:
        sampleRegistry (dict): The input data/MC registry as a dict.

    .. note::

        The YAML file needs to contain certain values for this to work. The
        top-level names are used throughout this script as labels for each set
        of data/MC. The key "sampleLabel" must correspond to a sample label used
        in `b2skim-stats-print`, so that the performance statistics can be
        retrieved from ``skimStats.json``. The remaining keys are used to
        construct the LPNs of the input datasets.

        Example of a data YAML file:

        .. highlight:: yaml

            proc9_exp3r1:
                sampleLabel: proc9_exp3
                LPNPrefix: /belle/Data
                inputReleaseNumber: release-03-02-02
                prodNumber: prod00008530
                inputDBGlobalTag: DB00000654
                procNumber: proc9
                experimentNumber: e0003
                beamEnergy: 4S
                inputDataLevel: mdst
                runNumbers:
                    - r02724
                    - r02801
                    - r02802

            proc9_exp3r2:
                sampleLabel: proc9_exp3
                LPNPrefix: /belle/Data
                inputReleaseNumber: release-03-02-02
                prodNumber: prod00008530
                inputDBGlobalTag: 654
                procNumber: proc9
                experimentNumber: e0003
                beamEnergy: 4S
                inputDataLevel: mdst
                runNumbers:
                    - r03237
                    - r03238
                    - r03239

        Example of an MC YAML file:

        .. highlight:: yaml

            MC12b_mixed:
                sampleLabel: MC12_mixedBGx1
                LPNPrefix: /belle/MC
                inputReleaseNumber: release-03-01-00
                inputDBGlobalTag: 547
                mcCampaign: MC12b
                prodNumber: prod00007392
                experimentNumber: s00/e1003
                beamEnergy: 4S
                mcType: mixed
                mcBackground: BGx1
                inputDataLevel: mdst
                runNumber: r00000

            # Can also contain list of prod numbers without prod0000 at start
            MC12b_charged:
                sampleLabel: MC12_chargedBGx1
                LPNPrefix: /belle/MC
                inputReleaseNumber: release-03-01-00
                inputDBGlobalTag: DB00000547
                mcCampaign: MC12b
                prodNumber:
                    - 7799
                    - 7802
                experimentNumber: s00/e1003
                beamEnergy: 4S
                mcType: charged
                mcBackground: BGx1
                inputDataLevel: mdst
                runNumber: r000000
    """
    with open(sampleRegistryYaml) as sampleRegistryFile:
        sampleRegistry = yaml.safe_load(sampleRegistryFile)

    verify_registry(sampleRegistry, mc)

    return sampleRegistry


def get_skim_stats_dict():
    """Read in the JSON output of ``b2skim-stats-print`` into a dict.

    Returns:
        skimStatsDict (dict): A dict containing the tested skim statistics.
    """
    # Assumes that skimStats.json is in the current directory
    with open("skimStats.json") as skimStatsFile:
        skimStatsDict = json.load(skimStatsFile)

    return skimStatsDict


def verify_registry(sampleRegistry, mc):
    """Check that the registry contains all the values that are expected. If a
    value is missing, print an error and exit.

    Args:
        sampleRegistry (dict): The input data/MC registry as a dict.
        mc (bool): Are these JSON files being produced for MC skims?
    """
    expectedMCEntries = ["sampleLabel", "LPNPrefix", "inputReleaseNumber",
                         "inputDBGlobalTag", "mcCampaign", "prodNumber",
                         "experimentNumber", "beamEnergy", "inputDataLevel",
                         "mcType", "mcBackground", "runNumber"]
    expectedDataEntries = ["LPNPrefix", "inputReleaseNumber", "inputDBGlobalTag",
                           "procNumber", "prodNumber", "experimentNumber",
                           "beamEnergy", "inputDataLevel", "runNumbers"]

    missingEntries = []
    if mc:
        missingEntries = [(sampleLabel, expectedEntry)
                          for (sampleLabel, sampleInfo) in sampleRegistry.items()
                          for expectedEntry in expectedMCEntries
                          if expectedEntry not in sampleInfo.keys()]
    else:
        missingEntries = [(sampleLabel, expectedEntry)
                          for (sampleLabel, sampleInfo) in sampleRegistry.items()
                          for expectedEntry in expectedDataEntries
                          if expectedEntry not in sampleInfo.keys()]

    if missingEntries:
        for sampleLabel, missingEntry in missingEntries:
            B2ERROR(f"Missing entry {missingEntry} for registry entry {sampleLabel}.")
        sys.exit(1)


def verify_stats_dict(args, sampleRegistry, skimStatsDict):
    """Verify that the required statistics are present in the stats dict. If any
    issues are found, print an error and exit.

    Args:
        args (argparse.ArgumentParser): An argparser expected to contain values
            for campaign name, starting prod number, and list of skims. Can also
            be any object which has these as attributes.
        sampleRegistry (dict): The input data/MC registry as a dict.
        skimStatsDict (dict): A dict containing the tested skim statistics.
    """
    skims = args.skims
    statistics = ["cpuTimePerEvent", "udstSizePerSkimmedEvent"]
    sampleLabels = [sampleInfo["sampleLabel"] for sampleInfo in sampleRegistry.values()]

    # Verify that all the requested skims have statistics listed
    missingSkims = [skim for skim in skims
                    if skim not in skimStatsDict.keys()]
    if missingSkims:
        for missingSkim in missingSkims:
            B2ERROR(f"Cannot find stats for {missingSkim} skim in skimStats.json."
                    "Perhaps you misspelled it or forgot to produce the stats "
                    "with `b2skim-stats-print`.")
        sys.exit(1)

    # Verify that all the requested samples were tested, and returned non-None values
    for skim, statistic, sampleLabel in product(skims, statistics, sampleLabels):
        try:
            statValue = skimStatsDict[skim][statistic][sampleLabel]
            if statValue is None:
                B2ERROR(f"The value for {statistic} for {skim} skim on {sampleLabel} sample"
                        "is `None`! This is no good.")
                sys.exit(1)
        except KeyError:
            B2ERROR(f"Missing value for {statistic} for {skim} skim on {sampleLabel} sample."
                    "Perhaps you misspelled it or forgot to produce the stats "
                    "with `b2skim-stats-print`.")
            sys.exit(1)


def get_base_directory(args):
    """Read the output base directory from the argparse arguments, and return
    that location as a `pathlib.Path` object. Checks that the given directory
    exists, and will print an error and exits if it is not.

    Args:
        args (argparse.ArgumentParser): An argument parser assumed to have the
            attribute `output_base_directory`.

    Returns:
        baseDirectory (pathlib.Path): The path of the base directory.
    """
    baseDirectory = Path(args.output_base_directory)
    if baseDirectory.is_dir():
        return baseDirectory
    else:
        B2ERROR(f"{args.output_base_directory} is not an existing directory.")
        sys.exit(1)


def get_output_directory(args, sampleRegistry):
    """Construct the output directory for the JSON files based on the given base
    directory.

    Args:
        args (argparse.ArgumentParser): An argument parser assumed to have the
            attributes `output_base_directory` and `release`.
        sampleRegistry (dict): The input data/MC registry as a dict.

    Returns:
        outputDirectory (pathlib.Path): The directory to write the JSON files into.
    """
    baseDirectory = get_base_directory(args)
    DBGlobalTag = get_DBGlobalTag(args.release)
    beamEnergy = get_beam_energy_from_registry(sampleRegistry)

    return Path(baseDirectory, args.campaign, args.release, DBGlobalTag, beamEnergy)


def get_lpn_list(sampleInfo, mc):
    """Construct the list of LPNs of a set of samples in the sample registry.

    Args:
        sampleInfo (dict): Dict of the sample registry. Registry format is
            explained in documentation of `read_registry_yaml`.
        mc (bool): Are these JSON files being produced for MC skims?

    Returns:
        LPNList (list): List of LPNs to be used for this set of jobs.
    """
    if mc:
        # Allow looping over prod numbers
        if isinstance(sampleInfo["prodNumber"], list):
            prodNumbers = sampleInfo["prodNumber"]
        else:
            prodNumbers = [sampleInfo["prodNumber"]]

        # Allow prod numbers to just be numbers in YAML file (without prod00.. at start)
        # This will pad a number with the correct number of zeros, and
        prodNumbers = [str(n) if str(n).startswith("prod00") else "prod" + str(n).zfill(8) for n in prodNumbers]

        # Similar for database global tag ID
        if not str(sampleInfo["inputDBGlobalTag"]).startswith("DB00"):
            sampleInfo["inputDBGlobalTag"] = "DB" + str(sampleInfo["inputDBGlobalTag"]).zfill(8)

        LPNList = [str(Path(sampleInfo["LPNPrefix"],
                            sampleInfo["inputReleaseNumber"],
                            sampleInfo["inputDBGlobalTag"],
                            sampleInfo["mcCampaign"],
                            prodNumber,
                            sampleInfo["experimentNumber"],
                            sampleInfo["beamEnergy"],
                            sampleInfo["runNumber"],
                            sampleInfo["mcType"],
                            sampleInfo["inputDataLevel"]))
                   for prodNumber in prodNumbers]
    else:
        if not str(sampleInfo["prodNumber"]).startswith("prod00"):
            sampleInfo["prodNumber"] = "prod" + str(sampleInfo["prodNumber"]).zfill(8)

        if not str(sampleInfo["inputDBGlobalTag"]).startswith("DB00"):
            sampleInfo["inputDBGlobalTag"] = "DB" + str(sampleInfo["inputDBGlobalTag"]).zfill(8)

        LPNList = [str(Path(sampleInfo["LPNPrefix"],
                            sampleInfo["inputReleaseNumber"],
                            sampleInfo["inputDBGlobalTag"],
                            sampleInfo["procNumber"],
                            sampleInfo["prodNumber"],
                            sampleInfo["experimentNumber"],
                            sampleInfo["beamEnergy"],
                            run,
                            sampleInfo["inputDataLevel"]))
                   for run in sampleInfo["runNumbers"]]

    return LPNList


@lru_cache()
def get_DBGlobalTag(releaseNumber):
    """Query the conditions database for the global tag to be used with a release.
    This function will look for global tags associated with all releases between
    the given release and the latest major release prior to it.

    * If only one global tag is used, then that is returned.

    * If more than one global tag is found, then the user ir prompted to select
      the one they want to use.

    * If no global tags are found, then an error is printed, and the script exits.

    Args:
        releaseNumber (str): The label of the release being used for the skims.

    Returns:
        DBGlobalTag (str): the database global tag, in the format DBxxxxxxxx.
    """
    # Check that the release number is of the correct form
    import re
    r = re.compile("^release(-[0-9]{2}){3}$")
    if not r.match(releaseNumber):
        B2ERROR("Release number must be of the form 'release-XX-XX-XX'.")
        sys.exit(1)

    initialReleaseNumber = releaseNumber

    _, majorNumber, minorNumber, patchNumber = releaseNumber.split('-')
    patchNumber = int(patchNumber)
    minorNumber = int(minorNumber)

    db = ConditionsDB()

    globalTags = []

    while minorNumber >= 0:
        releaseNumber = f"release-{majorNumber}-{str(minorNumber).zfill(2)}-{str(patchNumber).zfill(2)}"

        try:
            req = db.request("GET", f"/globalTag/{encode_name(releaseNumber)}")
            globalTagID = req.json()["globalTagId"]

            DBGlobalTag = "DB" + str(globalTagID).zfill(8)

            globalTags.append((DBGlobalTag, releaseNumber))

        except ConditionsDB.RequestError:
            # B2WARNING(f"Could not find global tag for {releaseNumber}.")
            pass

        if patchNumber == 0:
            # Decrease minor release number, set patch release number to 5
            # (can be set higher to check for more patch releases)
            minorNumber -= 1
            patchNumber = 5
        else:
            patchNumber -= 1

    if len(globalTags) == 1:
        # If only one available, use that
        DBGlobalTag, releaseNumber = globalTags[0]
        B2INFO(f"Using conditions database global tag {DBGlobalTag} for {releaseNumber}.")
        return DBGlobalTag

    elif len(globalTags) >= 1:
        # If multiple available, ask user what they want
        nGlobalTags = len(globalTags)
        B2INFO("Multiple conditions database global tags found.\n"
               f"Please select (one of 1--{nGlobalTags}).")
        for iGlobalTag, (DBGlobalTag, releaseNumber) in enumerate(globalTags):
            print(f"  [{iGlobalTag+1}] {releaseNumber}: {DBGlobalTag}")

        # Wait for user to select a global tag
        while True:
            selection = input()
            try:
                selection = int(selection) - 1
            except ValueError:
                pass

            if selection in range(nGlobalTags):
                break

        DBGlobalTag, releaseNumber = globalTags[selection]
        B2INFO(f"Using conditions database global tag {DBGlobalTag} for {releaseNumber}.")
        return DBGlobalTag

    else:
        # If none available, throw an error
        B2ERROR(f"Could not find any conditions database global tags for releases between\n"
                "release-{majorNumber}-{minorNumber}-00 and {initialReleaseNumber}.")
        sys.exit(1)


def get_HS06_per_event(skimStatsDict, skimName, sampleLabel):
    """Convert KEKCC CPU time into HEP-SPEC06 (the standard unit used for
    expressing CPU usage). According to
    `Confluence <https://confluence.desy.de/display/BI/Production+Definition>`_,
    the conversion factor is about 20.

    Args:
        skimStatsDict (dict): The skim stats read in from ``skimStats.json``.
        skimName (str): The name of the skim to retrieve the statistic for.
        sampleLabel (str): The label of the test sample to get the statistic for.

    Returns:
        HS06TimePerEvent (float): The converted time per event, now in units of HS06.
    """
    CPUTimePerEvent = skimStatsDict[skimName]["cpuTimePerEvent"][sampleLabel]
    HS06TimePerEvent = CPUTimePerEvent * 20
    return HS06TimePerEvent


def get_beam_energy_from_registry(sampleRegistry):
    """Read the input YAML file and retrieve the list of beam energies. Check
    for whether more than one beam energy is listed in the registry. Prints an
    error and exits if this is the case.

    Args:
        sampleRegistry (dict): The input data registry as a dict.

    Returns:
        beamEnergy (str): The beam energy as listed in the registry.
    """
    beamEnergies = [prod["beamEnergy"] for prod in sampleRegistry.values()]
    uniqueBeamEnergies = set(beamEnergies)

    if len(uniqueBeamEnergies) == 1:
        return list(uniqueBeamEnergies)[0]
    else:
        B2ERROR("More than one beam energy listed in input YAML file!")
        sys.exit(1)


def warn_local_script(args):
    """If a local script is given print a warning that a local script will be used.

    Args:
        args (argparse.ArgumentParser): An argparser expected to contain values
            `mc`,
    """
    if not args.local_skim_script:
        return

    if args.mc:
        dataOrMC = "MC"
    else:
        dataOrMC = "data"

    skimScript = args.local_skim_script
    if not skimScript.endswith('.py'):
        skimScript += '.py'

    localScriptDirectory = str(Path(dataOrMC, args.campaign, args.release, 'SkimScripts'))

    for skimName in args.skims:
        B2WARNING(f"Using local skim script! Please make sure to place sandbox file {skimScript}\n"
                  f"          in {Path(args.output_base_directory, localScriptDirectory).resolve()}\n"
                  f"          and modify {skimName}_Skim_Standalone.py to import this script.")


def make_request_dict(args, sampleRegistry, skimName, sampleLabel, prodNumber, LPNList):
    """Construct a dict for one skim and one set of data. Dict contains all the
    required fields for skim production.

    Args:
        args (argparse.ArgumentParser): An argparser expected to contain values
            for campaign name, starting prod number, and list of skims. Can also
            be any object which has these as attributes.
        sampleRegistry (dict): The input data registry as a dict.
        skimName (str): The name of the combined group of skims (*e.g.* feiSLCombined, BtoCharm).
        sampleLabel (str): Label in the registry for group of data in this job.
        prodNumber (int): Number to label this production request.
        LPNList (list): List of LPNs to include in the JSON file.

    Returns:
        skimRequestDict (dict): A dict ready to be saved as a JSON file.
    """
    sampleInfo = sampleRegistry[sampleLabel]
    statsSampleLabel = sampleInfo["sampleLabel"]  # Get label used by `b2skim-stats-print`

    skimStatsDict = get_skim_stats_dict()
    verify_stats_dict(args, sampleRegistry, skimStatsDict)

    individualSkims = combinedSkimsInfo[skimName]

    args.campaign = args.campaign

    if args.mc:
        dataOrMC = "MC"
        fabricationType = "MCSkim"
        LPNPrefix = "/belle/MC/skim"
    else:
        dataOrMC = "data"
        fabricationType = "DataSkim"
        LPNPrefix = "/belle/Data/skim"

    skimRequestDict = {
        "FabricationType": fabricationType,
        "ProductionName": f"{args.campaign}_{prodNumber}",
        "ProductionGroup": "skim",
        "Description": f"{args.campaign} skim campaign. {skimName} combined skim on {sampleLabel} {dataOrMC}.",
        "Release": args.release,
        "DBGlobalTag": get_DBGlobalTag(args.release),
        "Campaign": args.campaign,
        "BeamEnergy": get_beam_energy_from_registry(sampleRegistry),
        "TargetFileSize": 1024,
        "ExpectedEventCPUTime": get_HS06_per_event(skimStatsDict, skimName, statsSampleLabel),
        "ExpectedEventSize": skimStatsDict[skimName]["udstSizePerSkimmedEvent"][statsSampleLabel],
        "InputSandboxFilePrefix": f"{dataOrMC}/{args.campaign}/{args.release}/SkimScripts",
        "InputData": LPNList,
        "Priority": 8,
        "SteeringFile": f"{skimName}_Skim_Standalone.py",
        "SteeringFilePrefix": f"{dataOrMC}/{args.campaign}/{args.release}/SkimScripts",
        "LPNPrefix": LPNPrefix,
        "DataDescription": [
            {"SkimDecayMode": encodeSkimName(individualSkim),
             "DataLevel": "udst"} for individualSkim in individualSkims
        ]
    }

    # We only want the MCEventType to include the beam background level if the sample is BGx0
    if args.mc:
        if sampleInfo["mcBackground"] == "BGx0":
            skimRequestDict["MCEventType"] = sampleInfo["mcType"] + sampleInfo["mcBackground"]
        else:
            skimRequestDict["MCEventType"] = sampleInfo["mcType"]

    if args.local_skim_script:
        # Read in the name of the local skim module from the arguments
        skimScript = args.local_skim_script
        if not skimScript.endswith('.py'):
            skimScript += '.py'

        localScriptDirectory = str(Path(dataOrMC, args.campaign, args.release, 'SkimScripts'))
        skimRequestDict["InputSandboxFile"] = [skimScript]
        skimRequestDict["InputSandboxFilePrefix"] = localScriptDirectory

    return skimRequestDict


def write_json_files(sampleRegistry, args, outputDirectory):
    """Generate the dicts for each skim and registry entry, and write each to its own JSON file.

    Args:
        sampleRegistry (dict): The input data registry as a dict.
        args (argparse.ArgumentParser): An argparser expected to contain values
            for campaign name, starting prod number, and list of skims.
        outputDirectory (pathlib.Path, str): The location to save the JSON files.

    Returns:
        finalProdNumber (int): The greatest prod number used in the JSON files.
    """
    prodNumber = args.starting_prod_number - 1

    if args.one_lpn_per_json:
        B2INFO("Producing JSON files with one LPN per JSON file.")

    for skimName in args.skims:
        for sampleLabel, sampleInfo in sampleRegistry.items():

            SampleLPNList = get_lpn_list(sampleInfo, args.mc)

            # Make a list of LPN lists so that we can optionally have only LPN per JSON file
            if args.one_lpn_per_json:
                LPNLists = [[LPN] for LPN in SampleLPNList]
            else:
                LPNLists = [SampleLPNList]

            # MC campaign number is likely already in skim campaign name, so don't include it in sample label
            if args.mc:
                sampleLabelForFilename = sampleInfo["mcType"] + sampleInfo["mcBackground"]
            else:
                sampleLabelForFilename = sampleLabel

            for LPNList in LPNLists:
                prodNumber += 1
                skimRequestDict = make_request_dict(args, sampleRegistry, skimName, sampleLabel, prodNumber, LPNList)

                outputFileName = Path(outputDirectory, f"{args.campaign}_{prodNumber}_{skimName}_{sampleLabelForFilename}.json")
                if outputFileName.exists():
                    B2WARNING(f"Overwriting {outputFileName}")
                with open(outputFileName, "w") as outputFile:
                    json.dump(skimRequestDict, outputFile, indent=4)

        B2INFO(f"Make sure to copy {skimName}_Skim_Standalone.py to "
               f"{get_base_directory(args)}/{args.campaign}/{args.release}/SkimScripts/")

    return prodNumber


def get_argument_parser():
    """Define the argument parser.

    Returns:
        parser (argparse.ArgumentParser): A parser which defines the skim
            campaign, release number, and starting prod number.
    """
    parser = argparse.ArgumentParser(
        description="Produces JSON request files for grid production of skims.",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="example usage:\n    "
        "b2skim-prod-json RunRegistry_proc9.yaml --data -s LeptonicUntagged -n 9001 -c SKIMDATAx1 -r release-04-01-01 -o B2P/data/"
    )

    parser.add_argument("sampleRegistryYaml",
                        help="YAML file defining the samples produce JSON files for.")
    parser.add_argument("-s", "--skims", required=True, nargs="+",
                        metavar="SKIM", choices=combinedSkimsInfo.keys(),
                        help="List of skims to produce request files for. "
                        "Must be listed in `skiminfo.py`.")
    parser.add_argument("-n", "--starting-prod-number", required=True, type=int,
                        help="Starting prod number of the JSON files.")
    parser.add_argument("-o", "--output-base-directory", required=True,
                        help="Base directory for output. "
                        "This should be the base directory of the B2P/MC or B2P/data repo.")
    parser.add_argument("-c", "--campaign", required=True,
                        help="Name of the campaign, *e.g.* SKIMDATAx1.")
    parser.add_argument("-r", "--release", required=True,
                        help="The basf2 to release to be used, *e.g.* release-04-00-03")
    parser.add_argument("-l", "--local-skim-script",
                        help="File name of the local skim script to use, if any. *e.g.* ewp.py."
                        "Should not include any path before the file name.")
    parser.add_argument("-1", "--one-lpn-per-json", action="store_true",
                        help="Only include one LPN in each JSON file.")

    mcDataGroup = parser.add_mutually_exclusive_group(required=True)
    mcDataGroup.add_argument('--mc', '--MC', action='store_true',
                             help='Produce JSON files for MC.')
    mcDataGroup.add_argument('--data', '--Data', action='store_true',
                             help='Produce JSON files for data.')

    return parser


def main():
    """Reads in the YAML file, and creates the JSON files."""
    parser = get_argument_parser()
    args = parser.parse_args()

    sampleRegistry = read_registry_yaml(args.sampleRegistryYaml, args.mc)

    outputDirectory = get_output_directory(args, sampleRegistry)
    outputDirectory.mkdir(parents=True, exist_ok=True)

    finalProdNumber = write_json_files(sampleRegistry, args, outputDirectory)

    warn_local_script(args)
    B2INFO(f"Successfully generated {', '.join(args.skims)} JSON files for {', '.join(sampleRegistry.keys())} samples.")
    B2INFO(f"The JSON files were saved to {outputDirectory}")
    B2INFO(f"The prod numbers of these files range from {args.starting_prod_number} to {finalProdNumber}.")


if __name__ == "__main__":
    main()
