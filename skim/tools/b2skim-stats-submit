#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
A script to submit small skim test jobs, and save the output in a form to be
read by ``b2skim-stats-print``.
"""

import argparse
from functools import lru_cache
from pathlib import Path
import re
import subprocess
import sys

import yaml

from b2test_utils import working_directory
from basf2 import find_file, B2ERROR, B2INFO
from skim.registry import Registry
from skimExpertFunctions import get_test_file, get_eventN


def getAllSamples(mcCampaign):
    """Get lists of all MC and data samples to potentially test on.

    Args:
        mcCampaign (str): A label like ``MC12`` for the MC campaign to test on.

    Returns:
        mcSampleLabels (list): A list of internal MC sample labels (as used by
            `skimExpertFunctions.get_test_file`).
        dataSampleLabels (list): A list of internal data sample labels (as used by
            `skimExpertFunctions.get_test_file`).
    """
    mcSamples = [
        f"{mcCampaign}_mixedBGx1",
        f"{mcCampaign}_chargedBGx1",
        f"{mcCampaign}_ccbarBGx1",
        f"{mcCampaign}_uubarBGx1",
        f"{mcCampaign}_ddbarBGx1",
        f"{mcCampaign}_ssbarBGx1",
        f"{mcCampaign}_taupairBGx1",
        f"{mcCampaign}_mixedBGx0",
        f"{mcCampaign}_chargedBGx0",
        f"{mcCampaign}_ccbarBGx0",
        f"{mcCampaign}_uubarBGx0",
        f"{mcCampaign}_ddbarBGx0",
        f"{mcCampaign}_ssbarBGx0",
        f"{mcCampaign}_taupairBGx0",
    ]

    # For MC13 the low mult test samples exist (but they don't for MC12
    # and older) so here is a hack.
    # TODO: remove once when we regularly add the same low mult samples
    mcCampaignNumber = int(re.search(r'\d+', mcCampaign).group())
    if mcCampaignNumber > 12:
        mcSamples += [
            f"{mcCampaign}_ggBGx1",
            # f"{mcCampaign}_eeBGx1",
            f"{mcCampaign}_mumuBGx1",
            f"{mcCampaign}_eeeeBGx1",
            f"{mcCampaign}_eemumuBGx1",
        ]

    dataSamples = [
        "proc9_exp3",
        "proc9_exp7",
        "proc9_exp8",
        "bucket7_exp8",
        "proc10_exp7",
        "proc10_exp8",
    ]

    return mcSamples, dataSamples


class CustomHelpFormatter(argparse.HelpFormatter):
    """Custom formatter for argparse which prints the valid choices for an
    argument in the help string.
    """

    def _get_help_string(self, action):
        if action.choices:
            return (
                action.help + " Valid options are: " + ", ".join(action.choices) + "."
            )
        else:
            return action.help


def required_length(nMin):
    """Custom action for argparse to enforce a minimum number of arguments to an option."""
    class RequiredLength(argparse.Action):
        def __call__(self, parser, args, values, option_string=None):
            if len(values) < nMin:
                msg = "Argument '{self.dest}' requires at least {nMin} arguments."
                raise argparse.ArgumentTypeError(msg)
            setattr(args, self.dest, values)

    return RequiredLength


def getArgumentParser():
    """Construct the argument parser.

    Returns:
        parser (argparse.ArgumentParser): An argument parser which obtains its
            list of valid skim names from `skim.registry`.
    """
    parser = argparse.ArgumentParser(
        description=(
            "Submits test jobs for a given set of skims, and saves the output in a "
            "format to be read by ``b2skim-stats-print``. One or more standalone or "
            "combined skim names must be provided."
        ),
        formatter_class=CustomHelpFormatter,
    )

    SkimSelector = parser.add_mutually_exclusive_group(required=True)
    SkimSelector.add_argument(
        "-s",
        "--single",
        nargs="+",
        default=[],
        choices=["all"] + Registry.names,
        metavar="skim",
        help="List of individual skims to run.",
    )
    SkimSelector.add_argument(
        "-c",
        "--combined",
        nargs="+",
        action=required_length(2),
        metavar=("YAMLFile", "CombinedSkim"),
        help=(
            "List of combined skims to run. This flag expects as its first argument "
            "the path to a YAML defining the combined skims. All remaining arguments "
            "are the combined skims to test. The YAML file is simply a mapping of "
            "combined skim names to the invidivual skims comprising them. For example, "
            "``feiSL: [feiSLB0, feiSLBplus]``."
        ),
    )

    parser.add_argument(
        "-n",
        type=int,
        default=10000,
        metavar="nEventsPerSample",
        dest="nEventsPerSample",
        help=(
            "Number of events to run per sample. This input can be any positive "
            "number, but the actual number events run is limited to the size of the "
            "test files (~200,000 for MC files and ~20,000 for data files)."
        ),
    )
    parser.add_argument(
        "--mccampaign",
        default="MC13",
        choices=["MC12", "MC13"],
        help="The MC campaign to test on.",
    )

    sampleGroup = parser.add_mutually_exclusive_group()
    sampleGroup.add_argument(
        "--mconly", action="store_true", help="Test on only MC samples."
    )
    sampleGroup.add_argument(
        "--dataonly", action="store_true", help="Test on only data samples."
    )

    return parser


def getSamplesToRun(mcSamples, dataSamples, mcOnly=False, dataOnly=False):
    """Get a list of samples to be tested, filtered by whether the ``mcOnly``
    or ``dataOnly`` flags are provided.

    Args:
        mcSamples (list): A list of internal labels (as used by
            `skimExpertFunctions.get_test_file`) for MC samples to potentially
            test on.
        dataSamples (list): A list of internal labels (as used by
            `skimExpertFunctions.get_test_file`) for data samples to potentially
            test on.
        mcOnly (bool): Test only on MC samples.
        dataOnly (bool): Test only on data samples.

    Returns:
        samples (list): A list of internal labels for samples to be tested on.
    """
    if mcOnly:
        return mcSamples
    elif dataOnly:
        return dataSamples
    else:
        return mcSamples + dataSamples


def verify_combined_skims(CombinedSkimDefinitions, SkimsToRun):
    """Perform basic checks on combined skim definitions to catch issues early."""
    for CombinedSkim, skims in CombinedSkimDefinitions.items():
        # Check input YAML file only contains skims listed in registry
        for skim in skims:
            if skim not in Registry.names:
                raise ValueError(
                    f"Combined skim {CombinedSkim} contains unrecognised skim: {skim}."
                )

        # Check input YAML file does not list a skim twice in one combined skim
        duplicates = set([s for s in skims if skims.count(s) > 1])
        if duplicates:
            raise ValueError(
                f"Duplicates in combined skim {CombinedSkim}: {', '.join(duplicates)}."
            )


def submit_jobs(skims, samples, nEventsPerSample, *, CombinedSkimDefinitions={}):
    """Submit ``bsub`` jobs for each skim and for each test sample.

    Warns if any of the ``bsub`` submissions returned a non-zero exit code.
    Otherwise, prints a message summarising the job submission.

    Args:
        skims (list): A list of skim names to be run.
        samples (list): A list of internal labels for samples to be tested.
            These are read by `skimExpertFunctions.get_test_file`.
        nEventsPerSample (int): The number of events per file to run on.
        CombinedSkimDefinitions (dict(list)): A data structure specifyign which
            individual skims comprise the combined skims. If this argument is provided,
            then this function will assume we are running combined skims.
    """
    if CombinedSkimDefinitions:
        logDirectory = Path("log", "combined").resolve()

        # Save a copy of CombinedSkimDefinitions in the log directory
        with open(logDirectory / "CombinedSkims.yaml") as f:
            yaml.dump(CombinedSkimDefinitions, f)
    else:
        logDirectory = Path("log", "single").resolve()

    logDirectory.mkdir(parents=True, exist_ok=True)

    # Set up a cache for the metadata query, to reduce number of calls
    get_cached_eventN = lru_cache()(get_eventN)

    runner = find_file(str(Path("skim", "tools", "b2skim-run")))

    for skim in skims:
        jobIDs = []
        returnCodes = []

        for sample in samples:
            sampleFile = get_test_file(sample)

            if not Path(sampleFile).exists():
                B2ERROR(
                    f"Could not find test file {sampleFile}. `b2skim-stats-submit` is meant to be run on KEKCC."
                )
                sys.exit(1)

            logFile = Path(logDirectory, f"{skim}_{sample}.out")
            errFile = Path(logDirectory, f"{skim}_{sample}.err")
            jsonFile = Path(logDirectory, f"JobInformation_{skim}_{sample}.json")

            workingDirectory = Path(logDirectory, f"{skim}_{sample}")
            workingDirectory.mkdir(exist_ok=True)

            # Check that the number of events asked for doesn't exceed the number of events in the test file.
            # Removing this may confuse the stats printer.
            nTestEvents = min(nEventsPerSample, get_cached_eventN(sampleFile))

            if CombinedSkimDefinitions:
                arguments = [
                    "bsub", "-q", "l", "-oo", logFile, "-e", errFile, "-J",
                    f"{skim} {sample}", "basf2", runner, "--job-information", jsonFile, "-n",
                    str(nTestEvents), "-i", sampleFile, "--", "combined",
                    *CombinedSkimDefinitions[skim]
                ]
            else:
                arguments = [
                    "bsub", "-q", "l", "-oo", logFile, "-e", errFile, "-J",
                    f"{skim} {sample}", "basf2", runner, "--job-information", jsonFile, "-n",
                    str(nTestEvents), "-i", sampleFile, "--", "single", skim
                ]

            with working_directory(workingDirectory):
                process = subprocess.run(
                    arguments,
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                )

                jobIDs.append(re.findall("\d+", str(process.stdout))[0])
                returnCodes.append(process.returncode)

        if any(returnCodes):
            B2ERROR(
                f"An error occurred while submitting jobs for {skim} skim."
            )
        else:
            B2INFO(
                f"Running {skim} skim on {nEventsPerSample} events from test samples of {', '.join(samples)}. Job IDs:\n  "
                + "\n  ".join(jobIDs)
            )

    B2INFO(
        f"Log files will be written to {str(logDirectory)}. "
        "Once these jobs have finished, please run `b2skim-stats-print` "
        f"from the directory {str(Path.cwd().resolve())}."
    )


if __name__ == "__main__":
    parser = getArgumentParser()
    args = parser.parse_args()

    mcSamples, dataSamples = getAllSamples(args.mccampaign)
    samples = getSamplesToRun(mcSamples, dataSamples, args.mconly, args.dataonly)

    if args.single:
        skims = args.single
        submit_jobs(skims, samples, args.nEventsPerSample)
    else:
        with open(args.combined[0]) as YAMLFile:
            CombinedSkimDefinitions = yaml.safe_load(YAMLFile)
        skims = args.combined[1:]
        verify_combined_skims(CombinedSkimDefinitions, skims)
        submit_jobs(skims, samples, args.nEventsPerSample, CombinedSkimDefinitions=CombinedSkimDefinitions)
